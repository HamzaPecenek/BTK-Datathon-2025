{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2934ef9b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-29T07:00:10.972678Z",
     "iopub.status.busy": "2025-08-29T07:00:10.972297Z",
     "iopub.status.idle": "2025-08-29T07:00:19.649749Z",
     "shell.execute_reply": "2025-08-29T07:00:19.648960Z"
    },
    "papermill": {
     "duration": 8.686666,
     "end_time": "2025-08-29T07:00:19.651390",
     "exception": false,
     "start_time": "2025-08-29T07:00:10.964724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================\n",
    "# BTK Datathon 2025 — Baseline v1.1\n",
    "# =============================\n",
    "\n",
    "import os, sys, gc, math, json, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "CFG = {\n",
    "    \"seed\": 42,\n",
    "    \"seeds\": [42],                 # single seed (closer to the 1350 run)\n",
    "    \"cv_type\": \"time\",             # <<< back to time-based CV\n",
    "    \"use_log_target\": False,       # <<< raw target like v1\n",
    "    \"add_user_history\": True,      # <<< ON like v1\n",
    "    \"add_sequence_extras\": True,\n",
    "\n",
    "    \"lgb_params\": {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"mse\",\n",
    "        \"learning_rate\": 0.05,     # your good setting\n",
    "        \"num_leaves\": 63,          # v1-size trees\n",
    "        \"min_data_in_leaf\": 60,    # small extra regularization over v1=50\n",
    "        \"feature_fraction\": 0.85,\n",
    "        \"bagging_fraction\": 0.85,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"lambda_l2\": 2.0,\n",
    "        \"max_depth\": -1,\n",
    "        \"verbosity\": -1,\n",
    "        \"force_row_wise\": True,\n",
    "        \"extra_trees\": False,\n",
    "        \"seed\": 42, \"bagging_seed\": 42, \"feature_fraction_seed\": 42,\n",
    "        \"max_bin\": 255\n",
    "    },\n",
    "\n",
    "    \"n_splits\": 3,\n",
    "    \"n_splits_group\": 5,\n",
    "    \"early_stopping_rounds\": 300,\n",
    "    \"num_boost_round\": 6000,\n",
    "\n",
    "    # No hard cap; floor at 0 to match your best runs\n",
    "    \"clip\": {\"floor\": 0.0, \"cap\": 2000.0},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256bf186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T07:00:19.661223Z",
     "iopub.status.busy": "2025-08-29T07:00:19.659838Z",
     "iopub.status.idle": "2025-08-29T07:00:20.656603Z",
     "shell.execute_reply": "2025-08-29T07:00:20.655828Z"
    },
    "papermill": {
     "duration": 1.002597,
     "end_time": "2025-08-29T07:00:20.657968",
     "exception": false,
     "start_time": "2025-08-29T07:00:19.655371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/datathon-2025/train.csv /kaggle/input/datathon-2025/test.csv /kaggle/input/datathon-2025/sample_submission.csv\n",
      "Shapes: (141219, 7) (62951, 6) (30789, 2)\n",
      "\n",
      "Train columns:\n",
      " ['event_time', 'event_type', 'product_id', 'category_id', 'user_id', 'user_session', 'session_value']\n",
      "\n",
      "Test columns:\n",
      " ['event_time', 'event_type', 'product_id', 'category_id', 'user_id', 'user_session']\n",
      "\n",
      "Submission columns:\n",
      " ['user_session', 'session_value']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "      <th>session_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06-19 10:23:07+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_011223</td>\n",
       "      <td>CAT_00054</td>\n",
       "      <td>USER_097562</td>\n",
       "      <td>SESSION_158779</td>\n",
       "      <td>90.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-06-07 21:34:45+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_005519</td>\n",
       "      <td>CAT_00144</td>\n",
       "      <td>USER_006535</td>\n",
       "      <td>SESSION_029987</td>\n",
       "      <td>16.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-21 21:29:09+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_000577</td>\n",
       "      <td>CAT_00273</td>\n",
       "      <td>USER_047199</td>\n",
       "      <td>SESSION_022134</td>\n",
       "      <td>64.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 event_time event_type   product_id category_id      user_id  \\\n",
       "0 2025-06-19 10:23:07+00:00   ADD_CART  PROD_011223   CAT_00054  USER_097562   \n",
       "1 2025-06-07 21:34:45+00:00   ADD_CART  PROD_005519   CAT_00144  USER_006535   \n",
       "2 2025-06-21 21:29:09+00:00   ADD_CART  PROD_000577   CAT_00273  USER_047199   \n",
       "\n",
       "     user_session  session_value  \n",
       "0  SESSION_158779          90.29  \n",
       "1  SESSION_029987          16.39  \n",
       "2  SESSION_022134          64.27  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06-28 10:09:58+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_015000</td>\n",
       "      <td>CAT_00019</td>\n",
       "      <td>USER_109759</td>\n",
       "      <td>SESSION_164059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-06-25 11:57:50+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_023887</td>\n",
       "      <td>CAT_00010</td>\n",
       "      <td>USER_010614</td>\n",
       "      <td>SESSION_109583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-30 14:34:20+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_022673</td>\n",
       "      <td>CAT_00090</td>\n",
       "      <td>USER_041338</td>\n",
       "      <td>SESSION_171382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 event_time event_type   product_id category_id      user_id  \\\n",
       "0 2025-06-28 10:09:58+00:00   ADD_CART  PROD_015000   CAT_00019  USER_109759   \n",
       "1 2025-06-25 11:57:50+00:00   ADD_CART  PROD_023887   CAT_00010  USER_010614   \n",
       "2 2025-06-30 14:34:20+00:00   ADD_CART  PROD_022673   CAT_00090  USER_041338   \n",
       "\n",
       "     user_session  \n",
       "0  SESSION_164059  \n",
       "1  SESSION_109583  \n",
       "2  SESSION_171382  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_session</th>\n",
       "      <th>session_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SESSION_164059</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SESSION_109583</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SESSION_171382</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_session  session_value\n",
       "0  SESSION_164059            0.0\n",
       "1  SESSION_109583            0.0\n",
       "2  SESSION_171382            0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed(CFG[\"seed\"])\n",
    "\n",
    "# Kaggle input path(s)\n",
    "CANDIDATE_DIRS = [Path(\"/kaggle/input/datathon-2025\")]\n",
    "\n",
    "def find_csv(filename: str) -> Path:\n",
    "    for d in CANDIDATE_DIRS:\n",
    "        p = d / filename\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"Could not find {filename} in {CANDIDATE_DIRS}\")\n",
    "\n",
    "train_path = find_csv(\"train.csv\")\n",
    "test_path  = find_csv(\"test.csv\")\n",
    "sub_path   = find_csv(\"sample_submission.csv\")\n",
    "\n",
    "print(train_path, test_path, sub_path)\n",
    "\n",
    "# Auto-detect time column\n",
    "def detect_time_col(cols):\n",
    "    cand = [c for c in cols if c.lower() in (\"event_time\", \"event_timestamp\", \"timestamp\", \"time\", \"event_datetime\")]\n",
    "    if cand:\n",
    "        return cand[0]\n",
    "    cand = [c for c in cols if \"time\" in c.lower() or \"date\" in c.lower()]\n",
    "    return cand[0] if cand else None\n",
    "\n",
    "def read_df(path):\n",
    "    df = pd.read_csv(path)\n",
    "    tcol = detect_time_col(df.columns)\n",
    "    if tcol is None:\n",
    "        raise ValueError(\"Couldn't detect a time column. Please update detect_time_col().\")\n",
    "    df[tcol] = pd.to_datetime(df[tcol], errors=\"coerce\", utc=True)\n",
    "    if tcol != \"event_time\":\n",
    "        df = df.rename(columns={tcol: \"event_time\"})\n",
    "    return df\n",
    "\n",
    "train = read_df(train_path)\n",
    "test  = read_df(test_path)\n",
    "sub   = pd.read_csv(sub_path)\n",
    "\n",
    "print(\"Shapes:\", train.shape, test.shape, sub.shape)\n",
    "print(\"\\nTrain columns:\\n\", list(train.columns))\n",
    "print(\"\\nTest columns:\\n\", list(test.columns))\n",
    "print(\"\\nSubmission columns:\\n\", list(sub.columns))\n",
    "\n",
    "TARGET_COL = \"session_value\"\n",
    "assert TARGET_COL in train.columns and TARGET_COL not in test.columns, \"Target column check failed.\"\n",
    "\n",
    "display(train.head(3))\n",
    "display(test.head(3))\n",
    "display(sub.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ffb8b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T07:00:20.667803Z",
     "iopub.status.busy": "2025-08-29T07:00:20.667522Z",
     "iopub.status.idle": "2025-08-29T07:00:20.938202Z",
     "shell.execute_reply": "2025-08-29T07:00:20.937195Z"
    },
    "papermill": {
     "duration": 0.2775,
     "end_time": "2025-08-29T07:00:20.939830",
     "exception": false,
     "start_time": "2025-08-29T07:00:20.662330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 670 duplicate rows from train.\n",
      "Event types: ['ADD_CART', 'BUY', 'REMOVE_CART', 'VIEW']\n"
     ]
    }
   ],
   "source": [
    "before = len(train)\n",
    "train = train.drop_duplicates().reset_index(drop=True)\n",
    "after = len(train)\n",
    "print(f\"Dropped {before - after} duplicate rows from train.\")\n",
    "\n",
    "# Normalize frequent columns\n",
    "ID_USER = \"user_id\"\n",
    "ID_SESSION = \"user_session\"\n",
    "PRODUCT_COL = \"product_id\"\n",
    "CATEGORY_COL = \"category_id\"\n",
    "EVENT_COL = \"event_type\"\n",
    "\n",
    "expected_cols = [ID_USER, ID_SESSION, PRODUCT_COL, CATEGORY_COL, EVENT_COL, \"event_time\"]\n",
    "for c in expected_cols:\n",
    "    if c not in train.columns:\n",
    "        print(f\"Warning: expected column '{c}' not found in train.\")\n",
    "\n",
    "# Coerce types\n",
    "for df in (train, test):\n",
    "    for c in [ID_USER, ID_SESSION]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(str)\n",
    "    for c in [PRODUCT_COL, CATEGORY_COL, EVENT_COL]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(\"category\")\n",
    "\n",
    "# Align event type categories\n",
    "if EVENT_COL in train.columns:\n",
    "    all_types = sorted(list(set(train[EVENT_COL].dropna().unique()).union(set(test[EVENT_COL].dropna().unique()))))\n",
    "    train[EVENT_COL] = train[EVENT_COL].cat.set_categories(all_types)\n",
    "    test[EVENT_COL]  = test[EVENT_COL].cat.set_categories(all_types)\n",
    "print(\"Event types:\", train[EVENT_COL].cat.categories.tolist() if EVENT_COL in train.columns else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a30b9d71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T07:00:20.949633Z",
     "iopub.status.busy": "2025-08-29T07:00:20.949297Z",
     "iopub.status.idle": "2025-08-29T07:00:20.964407Z",
     "shell.execute_reply": "2025-08-29T07:00:20.963699Z"
    },
    "papermill": {
     "duration": 0.021629,
     "end_time": "2025-08-29T07:00:20.965760",
     "exception": false,
     "start_time": "2025-08-29T07:00:20.944131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Session-level feature builder\n",
    "def build_session_table(events: pd.DataFrame, is_train: bool) -> pd.DataFrame:\n",
    "    df = events.copy()\n",
    "    df = df.sort_values([\"user_session\", \"event_time\"]).reset_index(drop=True)\n",
    "\n",
    "    # Per-event flags\n",
    "    df[\"is_buy\"]  = (df[\"event_type\"] == \"BUY\").astype(int)\n",
    "    df[\"is_add\"]  = (df[\"event_type\"] == \"ADD_CART\").astype(int)\n",
    "    df[\"is_rem\"]  = (df[\"event_type\"] == \"REMOVE_CART\").astype(int)\n",
    "    df[\"is_view\"] = (df[\"event_type\"] == \"VIEW\").astype(int)\n",
    "\n",
    "    # Rank within session\n",
    "    df[\"ev_idx\"] = df.groupby(\"user_session\").cumcount()\n",
    "\n",
    "    # First/last event type\n",
    "    first_event = df.groupby(\"user_session\")[\"event_type\"].first().rename(\"first_event_type\")\n",
    "    last_event  = df.groupby(\"user_session\")[\"event_type\"].last().rename(\"last_event_type\")\n",
    "\n",
    "    # Start/end and duration\n",
    "    t_start = df.groupby(\"user_session\")[\"event_time\"].min().rename(\"session_start\")\n",
    "    t_end   = df.groupby(\"user_session\")[\"event_time\"].max().rename(\"session_end\")\n",
    "    duration = (t_end - t_start).dt.total_seconds().rename(\"duration_sec\")\n",
    "\n",
    "    # Counts & uniques\n",
    "    agg_counts = df.groupby(\"user_session\").agg(\n",
    "        n_events     = (\"event_type\", \"size\"),\n",
    "        n_products   = (\"product_id\", pd.Series.nunique),\n",
    "        n_categories = (\"category_id\", pd.Series.nunique),\n",
    "        n_event_types= (\"event_type\", pd.Series.nunique),\n",
    "        cnt_buy      = (\"is_buy\", \"sum\"),\n",
    "        cnt_add      = (\"is_add\", \"sum\"),\n",
    "        cnt_rem      = (\"is_rem\", \"sum\"),\n",
    "        cnt_view     = (\"is_view\", \"sum\"),\n",
    "    )\n",
    "\n",
    "    # Has buy\n",
    "    has_buy = (agg_counts[\"cnt_buy\"] > 0).astype(int).rename(\"has_buy\")\n",
    "\n",
    "    # First BUY index (or -1)\n",
    "    first_buy_idx = (\n",
    "        df[df[\"is_buy\"] == 1]\n",
    "        .groupby(\"user_session\")[\"ev_idx\"].min()\n",
    "        .reindex(agg_counts.index).fillna(-1).astype(int).rename(\"idx_first_buy\")\n",
    "    )\n",
    "\n",
    "    # Events after first BUY\n",
    "    events_after_buy = (agg_counts[\"n_events\"] - (first_buy_idx + 1)).clip(lower=0).rename(\"events_after_first_buy\")\n",
    "\n",
    "    # Adds/removes before first BUY\n",
    "    tmp = df.merge(first_buy_idx.rename(\"fb\"), left_on=\"user_session\", right_index=True, how=\"left\")\n",
    "    before_fb = tmp[\"ev_idx\"] <= tmp[\"fb\"]\n",
    "    cnt_add_before_buy = tmp.loc[before_fb, \"is_add\"].groupby(tmp[\"user_session\"]).sum().reindex(agg_counts.index).fillna(0).astype(int).rename(\"cnt_add_before_buy\")\n",
    "    cnt_rem_before_buy = tmp.loc[before_fb, \"is_rem\"].groupby(tmp[\"user_session\"]).sum().reindex(agg_counts.index).fillna(0).astype(int).rename(\"cnt_rem_before_buy\")\n",
    "\n",
    "    # Transitions\n",
    "    def count_transitions(g):\n",
    "        x = g[\"event_type\"].astype(str).values\n",
    "        if len(x) <= 1:\n",
    "            return 0\n",
    "        return int((x[1:] != x[:-1]).sum())\n",
    "    n_transitions = df.groupby(\"user_session\").apply(count_transitions).rename(\"n_transitions\")\n",
    "\n",
    "    # Time-of-day\n",
    "    start_hour = t_start.dt.hour.rename(\"start_hour\")\n",
    "    start_dow  = t_start.dt.dayofweek.rename(\"start_dow\")\n",
    "    start_day  = t_start.dt.day.rename(\"start_day\")\n",
    "\n",
    "    # Carry user_id\n",
    "    user_map = df.groupby(\"user_session\")[\"user_id\"].first().rename(\"user_id\")\n",
    "\n",
    "    # Assemble\n",
    "    sess = pd.concat(\n",
    "        [\n",
    "            t_start, t_end, duration, agg_counts,\n",
    "            has_buy, first_buy_idx, events_after_buy,\n",
    "            cnt_add_before_buy, cnt_rem_before_buy,\n",
    "            n_transitions, first_event, last_event,\n",
    "            start_hour, start_dow, start_day,\n",
    "            user_map,\n",
    "        ],\n",
    "        axis=1\n",
    "    ).reset_index()\n",
    "\n",
    "    if is_train:\n",
    "        t = df.groupby(\"user_session\")[\"session_value\"].first().reset_index()\n",
    "        sess = sess.merge(t, on=\"user_session\", how=\"left\")\n",
    "        chk = df.groupby(\"user_session\")[\"session_value\"].nunique().max()\n",
    "        if chk != 1:\n",
    "            print(\"WARNING: session_value is not constant within sessions.\")\n",
    "\n",
    "    # Cast categoricals\n",
    "    for c in [\"first_event_type\", \"last_event_type\"]:\n",
    "        if c in sess.columns:\n",
    "            sess[c] = sess[c].astype(\"category\")\n",
    "    sess[\"user_id\"] = sess[\"user_id\"].astype(str)\n",
    "    return sess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18dd6e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T07:00:20.975611Z",
     "iopub.status.busy": "2025-08-29T07:00:20.975274Z",
     "iopub.status.idle": "2025-08-29T07:01:02.128199Z",
     "shell.execute_reply": "2025-08-29T07:01:02.127176Z"
    },
    "papermill": {
     "duration": 41.163446,
     "end_time": "2025-08-29T07:01:02.133678",
     "exception": false,
     "start_time": "2025-08-29T07:00:20.970232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session tables rebuilt; `user_id` included.\n"
     ]
    }
   ],
   "source": [
    "train_sess = build_session_table(train, is_train=True)\n",
    "test_sess  = build_session_table(test,  is_train=False)\n",
    "print(\"Session tables rebuilt; `user_id` included.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dab34df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T07:01:02.143451Z",
     "iopub.status.busy": "2025-08-29T07:01:02.142914Z",
     "iopub.status.idle": "2025-08-29T07:01:02.153277Z",
     "shell.execute_reply": "2025-08-29T07:01:02.152372Z"
    },
    "papermill": {
     "duration": 0.016879,
     "end_time": "2025-08-29T07:01:02.154753",
     "exception": false,
     "start_time": "2025-08-29T07:01:02.137874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_user_history(train_sess: pd.DataFrame, test_sess: pd.DataFrame):\n",
    "    comb = pd.concat(\n",
    "        [train_sess.assign(_is_train=1), test_sess.assign(_is_train=0, **{TARGET_COL: np.nan})],\n",
    "        axis=0, ignore_index=True\n",
    "    ).sort_values([\"user_id\", \"session_start\"]).reset_index(drop=True)\n",
    "\n",
    "    # 1) Prior # sessions\n",
    "    comb[\"user_prev_n_sessions\"] = comb.groupby(\"user_id\").cumcount()\n",
    "\n",
    "    # 2) Prior buy-rate\n",
    "    g = comb.groupby(\"user_id\", sort=False)\n",
    "    pos = g.cumcount() + 1\n",
    "    prev_cnt = pos - 1\n",
    "    cum_sum_buy = g[\"has_buy\"].cumsum()\n",
    "    prev_sum_buy = cum_sum_buy - comb[\"has_buy\"]\n",
    "    comb[\"user_prev_buy_rate\"] = np.divide(\n",
    "        prev_sum_buy.astype(float), prev_cnt,\n",
    "        out=np.zeros_like(prev_sum_buy, dtype=float), where=prev_cnt > 0\n",
    "    )\n",
    "\n",
    "    # 3) Prior mean(session_value) with global backoff\n",
    "    comb[\"sv_notna\"]  = comb[TARGET_COL].notna().astype(int)\n",
    "    comb[\"sv_filled\"] = comb[TARGET_COL].fillna(0.0)\n",
    "    comb[\"cum_sum_sv\"] = g[\"sv_filled\"].cumsum()\n",
    "    comb[\"cum_cnt_sv\"] = g[\"sv_notna\"].cumsum()\n",
    "    prev_sum_sv = comb[\"cum_sum_sv\"] - comb[\"sv_filled\"]\n",
    "    prev_cnt_sv = comb[\"cum_cnt_sv\"] - comb[\"sv_notna\"]\n",
    "    prev_mean_sv = np.divide(\n",
    "        prev_sum_sv, prev_cnt_sv,\n",
    "        out=np.full(len(prev_sum_sv), np.nan, dtype=float), where=prev_cnt_sv > 0\n",
    "    )\n",
    "    global_mean_sv = float(train_sess[TARGET_COL].mean())\n",
    "    comb[\"user_prev_mean_sv\"] = np.where(np.isnan(prev_mean_sv), global_mean_sv, prev_mean_sv)\n",
    "\n",
    "    comb = comb.drop(columns=[\"sv_notna\",\"sv_filled\",\"cum_sum_sv\",\"cum_cnt_sv\"])\n",
    "\n",
    "    train_hist = comb[comb[\"_is_train\"] == 1].drop(columns=[\"_is_train\"])\n",
    "    test_hist  = comb[comb[\"_is_train\"] == 0].drop(columns=[\"_is_train\"])\n",
    "\n",
    "    for df in (train_hist, test_hist):\n",
    "        df[\"user_prev_n_sessions\"] = df[\"user_prev_n_sessions\"].astype(int)\n",
    "        df[\"user_prev_buy_rate\"]   = df[\"user_prev_buy_rate\"].astype(float)\n",
    "        df[\"user_prev_mean_sv\"]    = df[\"user_prev_mean_sv\"].astype(float)\n",
    "\n",
    "    return train_hist, test_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "286bab2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T07:01:02.164317Z",
     "iopub.status.busy": "2025-08-29T07:01:02.163998Z",
     "iopub.status.idle": "2025-08-29T07:01:02.654136Z",
     "shell.execute_reply": "2025-08-29T07:01:02.653411Z"
    },
    "papermill": {
     "duration": 0.496299,
     "end_time": "2025-08-29T07:01:02.655376",
     "exception": false,
     "start_time": "2025-08-29T07:01:02.159077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user history features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_prev_n_sessions</th>\n",
       "      <th>user_prev_buy_rate</th>\n",
       "      <th>user_prev_mean_sv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.19813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.19813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.19813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_prev_n_sessions  user_prev_buy_rate  user_prev_mean_sv\n",
       "0                     0                 0.0           42.19813\n",
       "1                     0                 0.0           42.19813\n",
       "2                     0                 0.0           42.19813"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if CFG[\"add_user_history\"]:\n",
    "    train_sess, test_sess = add_user_history(train_sess, test_sess)\n",
    "    print(\"Added user history features.\")\n",
    "    display(train_sess.filter(like=\"user_prev\").head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b0ca24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T07:01:02.665651Z",
     "iopub.status.busy": "2025-08-29T07:01:02.665098Z",
     "iopub.status.idle": "2025-08-29T07:01:02.710920Z",
     "shell.execute_reply": "2025-08-29T07:01:02.709889Z"
    },
    "papermill": {
     "duration": 0.05278,
     "end_time": "2025-08-29T07:01:02.712376",
     "exception": false,
     "start_time": "2025-08-29T07:01:02.659596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 35\n",
      "Categorical: ['first_event_type', 'last_event_type']\n",
      "Numeric: ['n_events', 'n_products', 'n_categories', 'n_event_types', 'cnt_buy', 'cnt_add', 'cnt_rem', 'cnt_view', 'duration_sec', 'has_buy', 'idx_first_buy', 'events_after_first_buy', 'cnt_add_before_buy', 'cnt_rem_before_buy', 'n_transitions', 'start_hour', 'start_dow', 'start_day', 'user_prev_n_sessions', 'user_prev_buy_rate', 'user_prev_mean_sv', 'log1p_n_events', 'log1p_n_products', 'log1p_n_categories', 'log1p_duration_sec', 'log1p_cnt_buy', 'log1p_cnt_add', 'log1p_cnt_rem', 'log1p_cnt_view', 'rate_add_per_event', 'rate_rem_per_event', 'rate_buy_per_event', 'events_per_min']\n"
     ]
    }
   ],
   "source": [
    "# Low-risk numeric enrichments (log1p + simple rates)\n",
    "def enrich_small_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    eps = 1e-6\n",
    "    for c in [\"n_events\", \"n_products\", \"n_categories\", \"duration_sec\",\n",
    "              \"cnt_buy\", \"cnt_add\", \"cnt_rem\", \"cnt_view\"]:\n",
    "        if c in df:\n",
    "            df[f\"log1p_{c}\"] = np.log1p(df[c].astype(float))\n",
    "\n",
    "    if \"n_events\" in df:\n",
    "        denom_ev = df[\"n_events\"].clip(lower=1).astype(float)\n",
    "        if \"cnt_add\" in df: df[\"rate_add_per_event\"] = df[\"cnt_add\"] / denom_ev\n",
    "        if \"cnt_rem\" in df: df[\"rate_rem_per_event\"] = df[\"cnt_rem\"] / denom_ev\n",
    "        if \"cnt_buy\" in df: df[\"rate_buy_per_event\"] = df[\"cnt_buy\"] / denom_ev\n",
    "\n",
    "    if \"duration_sec\" in df and \"n_events\" in df:\n",
    "        df[\"events_per_min\"] = df[\"n_events\"] / (df[\"duration_sec\"] / 60.0 + eps)\n",
    "    return df\n",
    "\n",
    "train_sess = enrich_small_features(train_sess)\n",
    "test_sess  = enrich_small_features(test_sess)\n",
    "\n",
    "# Feature columns\n",
    "categorical_cols = [\"first_event_type\", \"last_event_type\"]\n",
    "numeric_cols = [\n",
    "    \"n_events\", \"n_products\", \"n_categories\", \"n_event_types\",\n",
    "    \"cnt_buy\", \"cnt_add\", \"cnt_rem\", \"cnt_view\",\n",
    "    \"duration_sec\", \"has_buy\", \"idx_first_buy\", \"events_after_first_buy\",\n",
    "    \"cnt_add_before_buy\", \"cnt_rem_before_buy\", \"n_transitions\",\n",
    "    \"start_hour\", \"start_dow\", \"start_day\",\n",
    "]\n",
    "if CFG[\"add_user_history\"]:\n",
    "    numeric_cols += [\"user_prev_n_sessions\", \"user_prev_buy_rate\", \"user_prev_mean_sv\"]\n",
    "\n",
    "# add enrichments\n",
    "extra_feats = [\n",
    "    *(f\"log1p_{c}\" for c in [\"n_events\",\"n_products\",\"n_categories\",\"duration_sec\",\"cnt_buy\",\"cnt_add\",\"cnt_rem\",\"cnt_view\"]),\n",
    "    \"rate_add_per_event\",\"rate_rem_per_event\",\"rate_buy_per_event\",\"events_per_min\"\n",
    "]\n",
    "numeric_cols += [c for c in extra_feats if c in train_sess.columns]\n",
    "\n",
    "# ensure existence\n",
    "categorical_cols = [c for c in categorical_cols if c in train_sess.columns]\n",
    "numeric_cols = [c for c in numeric_cols if c in train_sess.columns]\n",
    "FEATS = categorical_cols + numeric_cols\n",
    "\n",
    "print(\"Num features:\", len(FEATS))\n",
    "print(\"Categorical:\", categorical_cols)\n",
    "print(\"Numeric:\", [c for c in FEATS if c not in categorical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cf9ca22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T07:01:02.724198Z",
     "iopub.status.busy": "2025-08-29T07:01:02.723381Z",
     "iopub.status.idle": "2025-08-29T07:01:02.729681Z",
     "shell.execute_reply": "2025-08-29T07:01:02.728748Z"
    },
    "papermill": {
     "duration": 0.014098,
     "end_time": "2025-08-29T07:01:02.731067",
     "exception": false,
     "start_time": "2025-08-29T07:01:02.716969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features (final): 23\n"
     ]
    }
   ],
   "source": [
    "# After defining extra_feats and numeric_cols\n",
    "use_enrichments = False  # <<< toggle OFF for this last run\n",
    "if not use_enrichments:\n",
    "    numeric_cols = [c for c in numeric_cols if c not in set(extra_feats)]\n",
    "\n",
    "# Rebuild FEATS\n",
    "categorical_cols = [c for c in categorical_cols if c in train_sess.columns]\n",
    "numeric_cols     = [c for c in numeric_cols if c in train_sess.columns]\n",
    "FEATS = categorical_cols + numeric_cols\n",
    "\n",
    "print(\"Num features (final):\", len(FEATS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0fcc790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T07:01:02.740958Z",
     "iopub.status.busy": "2025-08-29T07:01:02.740693Z",
     "iopub.status.idle": "2025-08-29T07:01:02.766275Z",
     "shell.execute_reply": "2025-08-29T07:01:02.765394Z"
    },
    "papermill": {
     "duration": 0.03242,
     "end_time": "2025-08-29T07:01:02.767968",
     "exception": false,
     "start_time": "2025-08-29T07:01:02.735548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70736, 23), (30789, 23))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target\n",
    "if CFG[\"use_log_target\"]:\n",
    "    train_sess[\"target\"] = np.log1p(train_sess[TARGET_COL].clip(lower=0))\n",
    "else:\n",
    "    train_sess[\"target\"] = train_sess[TARGET_COL].astype(float)\n",
    "\n",
    "# Categorical dtype for LightGBM\n",
    "for c in categorical_cols:\n",
    "    train_sess[c] = train_sess[c].astype(\"category\")\n",
    "    test_sess[c]  = test_sess[c].astype(\"category\")\n",
    "\n",
    "X = train_sess[FEATS].copy()\n",
    "y = train_sess[\"target\"].values\n",
    "X_test = test_sess[FEATS].copy()\n",
    "\n",
    "# label-aligned series\n",
    "y_s = pd.Series(train_sess[\"target\"].values, index=X.index)\n",
    "\n",
    "X.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc4858b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T07:01:02.779278Z",
     "iopub.status.busy": "2025-08-29T07:01:02.778654Z",
     "iopub.status.idle": "2025-08-29T07:01:02.860305Z",
     "shell.execute_reply": "2025-08-29T07:01:02.859352Z"
    },
    "papermill": {
     "duration": 0.088874,
     "end_time": "2025-08-29T07:01:02.861814",
     "exception": false,
     "start_time": "2025-08-29T07:01:02.772940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Fold 0: val window 2025-06-01 00:00:24+00:00 → 2025-06-07 03:06:40+00:00, size=23579\n",
      "Time Fold 1: val window 2025-06-07 03:06:51+00:00 → 2025-06-14 09:07:02+00:00, size=23579\n",
      "Time Fold 2: val window 2025-06-14 09:07:35+00:00 → 2025-06-21 23:58:05+00:00, size=23578\n"
     ]
    }
   ],
   "source": [
    "def make_time_folds(df: pd.DataFrame, n_splits=3, date_col=\"session_start\"):\n",
    "    df_sorted = df.sort_values(date_col).reset_index()\n",
    "    n = len(df_sorted)\n",
    "    fold_sizes = [n // n_splits] * n_splits\n",
    "    for i in range(n % n_splits):\n",
    "        fold_sizes[i] += 1\n",
    "    idxs, start = [], 0\n",
    "    for fs in fold_sizes:\n",
    "        end = start + fs\n",
    "        idxs.append(df_sorted.loc[start:end-1, \"index\"].values)\n",
    "        start = end\n",
    "    folds = []\n",
    "    for i in range(n_splits):\n",
    "        val_idx = idxs[i]\n",
    "        tr_idx = np.concatenate([idxs[j] for j in range(n_splits) if j != i])\n",
    "        folds.append((tr_idx, val_idx))\n",
    "    return folds\n",
    "\n",
    "def make_group_folds(df: pd.DataFrame, n_splits=5, group_col=\"user_id\"):\n",
    "    idx = np.arange(len(df))\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    return [(tr, va) for tr, va in gkf.split(idx, groups=df[group_col].values)]\n",
    "\n",
    "# quick view of time-fold windows (unchanged)\n",
    "folds_preview = make_time_folds(train_sess, n_splits=CFG[\"n_splits\"], date_col=\"session_start\")\n",
    "for i, (_, va) in enumerate(folds_preview):\n",
    "    d1 = train_sess.loc[va, \"session_start\"].min()\n",
    "    d2 = train_sess.loc[va, \"session_start\"].max()\n",
    "    print(f\"Time Fold {i}: val window {d1} → {d2}, size={len(va)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d763396",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T07:01:02.872060Z",
     "iopub.status.busy": "2025-08-29T07:01:02.871751Z",
     "iopub.status.idle": "2025-08-29T07:02:06.875990Z",
     "shell.execute_reply": "2025-08-29T07:02:06.875087Z"
    },
    "papermill": {
     "duration": 64.011292,
     "end_time": "2025-08-29T07:02:06.877350",
     "exception": false,
     "start_time": "2025-08-29T07:01:02.866058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[seed 42] Fold 0: best_iter=1744, val_size=23579\n",
      "[seed 42] Fold 1: best_iter=224, val_size=23579\n",
      "[seed 42] Fold 2: best_iter=3232, val_size=23578\n",
      "OOF MSE (post-processed): 379.2776\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnt_buy</td>\n",
       "      <td>5.042703e+08</td>\n",
       "      <td>3901.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>events_after_first_buy</td>\n",
       "      <td>1.015940e+08</td>\n",
       "      <td>3968.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>has_buy</td>\n",
       "      <td>6.311919e+07</td>\n",
       "      <td>81.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnt_add</td>\n",
       "      <td>2.909713e+07</td>\n",
       "      <td>3471.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_products</td>\n",
       "      <td>2.862070e+07</td>\n",
       "      <td>4537.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>duration_sec</td>\n",
       "      <td>2.672447e+07</td>\n",
       "      <td>18991.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n_events</td>\n",
       "      <td>2.393521e+07</td>\n",
       "      <td>4409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n_categories</td>\n",
       "      <td>1.847591e+07</td>\n",
       "      <td>4480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>start_hour</td>\n",
       "      <td>1.514121e+07</td>\n",
       "      <td>13983.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>idx_first_buy</td>\n",
       "      <td>8.379292e+06</td>\n",
       "      <td>2566.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cnt_rem</td>\n",
       "      <td>7.595875e+06</td>\n",
       "      <td>2658.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>last_event_type</td>\n",
       "      <td>7.124302e+06</td>\n",
       "      <td>1431.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>user_prev_n_sessions</td>\n",
       "      <td>6.772365e+06</td>\n",
       "      <td>4248.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>start_dow</td>\n",
       "      <td>5.977552e+06</td>\n",
       "      <td>6553.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>user_prev_mean_sv</td>\n",
       "      <td>5.968767e+06</td>\n",
       "      <td>12255.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>start_day</td>\n",
       "      <td>5.761645e+06</td>\n",
       "      <td>8182.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>n_event_types</td>\n",
       "      <td>5.195171e+06</td>\n",
       "      <td>1462.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>n_transitions</td>\n",
       "      <td>4.889850e+06</td>\n",
       "      <td>2312.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cnt_add_before_buy</td>\n",
       "      <td>4.745278e+06</td>\n",
       "      <td>1132.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cnt_view</td>\n",
       "      <td>4.006760e+06</td>\n",
       "      <td>2965.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>first_event_type</td>\n",
       "      <td>3.944015e+06</td>\n",
       "      <td>1638.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cnt_rem_before_buy</td>\n",
       "      <td>2.561104e+06</td>\n",
       "      <td>1263.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>user_prev_buy_rate</td>\n",
       "      <td>8.218031e+05</td>\n",
       "      <td>973.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature          gain         split\n",
       "0                  cnt_buy  5.042703e+08   3901.333333\n",
       "1   events_after_first_buy  1.015940e+08   3968.000000\n",
       "2                  has_buy  6.311919e+07     81.666667\n",
       "3                  cnt_add  2.909713e+07   3471.000000\n",
       "4               n_products  2.862070e+07   4537.333333\n",
       "5             duration_sec  2.672447e+07  18991.333333\n",
       "6                 n_events  2.393521e+07   4409.000000\n",
       "7             n_categories  1.847591e+07   4480.000000\n",
       "8               start_hour  1.514121e+07  13983.333333\n",
       "9            idx_first_buy  8.379292e+06   2566.666667\n",
       "10                 cnt_rem  7.595875e+06   2658.666667\n",
       "11         last_event_type  7.124302e+06   1431.666667\n",
       "12    user_prev_n_sessions  6.772365e+06   4248.333333\n",
       "13               start_dow  5.977552e+06   6553.666667\n",
       "14       user_prev_mean_sv  5.968767e+06  12255.666667\n",
       "15               start_day  5.761645e+06   8182.000000\n",
       "16           n_event_types  5.195171e+06   1462.333333\n",
       "17           n_transitions  4.889850e+06   2312.000000\n",
       "18      cnt_add_before_buy  4.745278e+06   1132.666667\n",
       "19                cnt_view  4.006760e+06   2965.000000\n",
       "20        first_event_type  3.944015e+06   1638.333333\n",
       "21      cnt_rem_before_buy  2.561104e+06   1263.666667\n",
       "22      user_prev_buy_rate  8.218031e+05    973.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred summary (post-processed):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    30789.000000\n",
       "mean        43.576480\n",
       "std         44.569802\n",
       "min          0.000000\n",
       "25%         23.572702\n",
       "50%         29.497648\n",
       "75%         42.658338\n",
       "max        909.201589\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==== FIXED Cell 11: multi-seed, CV realism, with index → position mapping ====\n",
    "oof_all = np.zeros(len(X), dtype=float)\n",
    "test_preds_seeds = []\n",
    "feat_imps = []\n",
    "\n",
    "global_mean_sv = float(train_sess[TARGET_COL].mean())\n",
    "X_index = pd.Index(X.index)  # to map label indices to positions\n",
    "\n",
    "for seed in CFG[\"seeds\"]:\n",
    "    lgb_params = CFG[\"lgb_params\"].copy()\n",
    "    lgb_params.update({\"seed\": seed, \"bagging_seed\": seed, \"feature_fraction_seed\": seed})\n",
    "    set_seed(seed)\n",
    "\n",
    "    if CFG[\"cv_type\"] == \"time\":\n",
    "        folds = make_time_folds(train_sess, n_splits=CFG[\"n_splits\"], date_col=\"session_start\")\n",
    "    else:\n",
    "        folds = make_group_folds(train_sess, n_splits=CFG[\"n_splits_group\"], group_col=\"user_id\")\n",
    "\n",
    "    oof_seed = np.zeros(len(X), dtype=float)\n",
    "    best_iters = []\n",
    "\n",
    "    for i, (tr_idx, va_idx) in enumerate(folds):\n",
    "        # Map label indices -> positional indices for any ndarray assignments\n",
    "        tr_pos = X_index.get_indexer(tr_idx)\n",
    "        va_pos = X_index.get_indexer(va_idx)\n",
    "\n",
    "        # Guard: no missing labels (-1) and all within bounds\n",
    "        if (tr_pos < 0).any() or (va_pos < 0).any():\n",
    "            raise ValueError(f\"Fold {i}: found indices not present in X.index. \"\n",
    "                             f\"Try resetting indices before building folds.\")\n",
    "        if (va_pos >= len(X)).any() or (tr_pos >= len(X)).any():\n",
    "            raise ValueError(f\"Fold {i}: positional indices out of bounds.\")\n",
    "\n",
    "        # Use .iloc with positions for safety; .loc with labels would also work\n",
    "        X_tr, y_tr = X.iloc[tr_pos], y_s.iloc[tr_pos].values\n",
    "        X_va, y_va = X.iloc[va_pos], y_s.iloc[va_pos].values\n",
    "\n",
    "        # Group CV realism: neutralize user history for val users (simulate unseen)\n",
    "        if CFG[\"cv_type\"] != \"time\":\n",
    "            X_va = X_va.copy()\n",
    "            if \"user_prev_mean_sv\" in X_va: X_va[\"user_prev_mean_sv\"] = global_mean_sv\n",
    "            if \"user_prev_buy_rate\" in X_va: X_va[\"user_prev_buy_rate\"] = 0.0\n",
    "            if \"user_prev_n_sessions\" in X_va: X_va[\"user_prev_n_sessions\"] = 0\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_tr, label=y_tr, categorical_feature=categorical_cols, free_raw_data=False)\n",
    "        lgb_valid = lgb.Dataset(X_va, label=y_va, categorical_feature=categorical_cols, free_raw_data=False)\n",
    "\n",
    "        model = lgb.train(\n",
    "            lgb_params, lgb_train,\n",
    "            num_boost_round=CFG[\"num_boost_round\"],\n",
    "            valid_sets=[lgb_train, lgb_valid],\n",
    "            valid_names=[\"train\", \"valid\"],\n",
    "            callbacks=[lgb.early_stopping(CFG[\"early_stopping_rounds\"], verbose=False)]\n",
    "        )\n",
    "        best_iters.append(model.best_iteration)\n",
    "\n",
    "        pred_va = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "        if CFG[\"use_log_target\"]:\n",
    "            pred_va = np.expm1(pred_va).clip(min=0)\n",
    "\n",
    "        # Apply the same post-process as test-time\n",
    "        pred_va = np.clip(pred_va, CFG[\"clip\"][\"floor\"], CFG[\"clip\"][\"cap\"])\n",
    "\n",
    "        # <<< KEY FIX: assign via positional indices >>>\n",
    "        oof_seed[va_pos] = pred_va\n",
    "\n",
    "        fi = pd.DataFrame({\n",
    "            \"feature\": FEATS,\n",
    "            \"gain\": model.feature_importance(importance_type=\"gain\"),\n",
    "            \"split\": model.feature_importance(importance_type=\"split\"),\n",
    "            \"fold\": i,\n",
    "            \"seed\": seed,\n",
    "        })\n",
    "        feat_imps.append(fi)\n",
    "\n",
    "        print(f\"[seed {seed}] Fold {i}: best_iter={model.best_iteration}, val_size={len(va_pos)}\")\n",
    "\n",
    "    oof_all += oof_seed / len(CFG[\"seeds\"])\n",
    "\n",
    "    full_iters = int(np.mean(best_iters))\n",
    "    full_ds = lgb.Dataset(X, label=y_s.values, categorical_feature=categorical_cols, free_raw_data=False)\n",
    "    full_model = lgb.train(lgb_params, full_ds, num_boost_round=full_iters)\n",
    "\n",
    "    pred_test = full_model.predict(X_test)\n",
    "    if CFG[\"use_log_target\"]:\n",
    "        pred_test = np.expm1(pred_test).clip(min=0)\n",
    "    pred_test = np.clip(pred_test, CFG[\"clip\"][\"floor\"], CFG[\"clip\"][\"cap\"])\n",
    "    test_preds_seeds.append(pred_test)\n",
    "\n",
    "# OOF MSE on raw scale\n",
    "if CFG[\"use_log_target\"]:\n",
    "    y_raw = np.expm1(y_s.values)\n",
    "    oof_mse = mean_squared_error(y_raw, oof_all)\n",
    "else:\n",
    "    oof_mse = mean_squared_error(y_s.values, oof_all)\n",
    "print(f\"OOF MSE (post-processed): {oof_mse:,.4f}\")\n",
    "\n",
    "feat_importance = (\n",
    "    pd.concat(feat_imps, ignore_index=True)\n",
    "      .groupby(\"feature\")[[\"gain\",\"split\"]].mean()\n",
    "      .sort_values(\"gain\", ascending=False).reset_index()\n",
    ")\n",
    "display(feat_importance.head(30))\n",
    "\n",
    "test_pred = np.mean(test_preds_seeds, axis=0)\n",
    "print(\"Pred summary (post-processed):\")\n",
    "display(pd.Series(test_pred).describe())\n",
    "\n",
    "oof = oof_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b20b8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T07:02:06.889188Z",
     "iopub.status.busy": "2025-08-29T07:02:06.888888Z",
     "iopub.status.idle": "2025-08-29T07:02:07.008761Z",
     "shell.execute_reply": "2025-08-29T07:02:07.007870Z"
    },
    "papermill": {
     "duration": 0.12719,
     "end_time": "2025-08-29T07:02:07.010124",
     "exception": false,
     "start_time": "2025-08-29T07:02:06.882934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: submission_baseline_v1_0_3.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_session</th>\n",
       "      <th>session_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SESSION_164059</td>\n",
       "      <td>148.859200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SESSION_109583</td>\n",
       "      <td>43.520985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SESSION_171382</td>\n",
       "      <td>41.217141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SESSION_137110</td>\n",
       "      <td>32.355216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SESSION_146503</td>\n",
       "      <td>193.892049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_session  session_value\n",
       "0  SESSION_164059     148.859200\n",
       "1  SESSION_109583      43.520985\n",
       "2  SESSION_171382      41.217141\n",
       "3  SESSION_137110      32.355216\n",
       "4  SESSION_146503     193.892049"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Expect submission format: [\"user_session\", \"session_value\"]\n",
    "sub_out = sub.copy()\n",
    "key = \"user_session\"\n",
    "\n",
    "# Map predictions by user_session (test_sess has one row per session)\n",
    "pred_map = dict(zip(test_sess[key], test_pred))\n",
    "sub_out[TARGET_COL] = sub_out[key].map(pred_map).fillna(CFG[\"clip\"][\"floor\"])\n",
    "\n",
    "save_name = \"submission_baseline_v1_0_3.csv\"\n",
    "sub_out.to_csv(save_name, index=False)\n",
    "print(\"Saved:\", save_name)\n",
    "display(sub_out.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec64d8fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T07:02:07.021929Z",
     "iopub.status.busy": "2025-08-29T07:02:07.021641Z",
     "iopub.status.idle": "2025-08-29T07:02:07.126634Z",
     "shell.execute_reply": "2025-08-29T07:02:07.125737Z"
    },
    "papermill": {
     "duration": 0.11253,
     "end_time": "2025-08-29T07:02:07.128060",
     "exception": false,
     "start_time": "2025-08-29T07:02:07.015530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF MSE (raw): 379.27764570970294\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>oof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70736.000000</td>\n",
       "      <td>70736.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.198130</td>\n",
       "      <td>41.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47.552369</td>\n",
       "      <td>43.670772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.380000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.530000</td>\n",
       "      <td>23.153118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.750000</td>\n",
       "      <td>28.390345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.620000</td>\n",
       "      <td>39.919078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2328.660000</td>\n",
       "      <td>1265.938009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  y           oof\n",
       "count  70736.000000  70736.000000\n",
       "mean      42.198130     41.917969\n",
       "std       47.552369     43.670772\n",
       "min        5.380000      0.000000\n",
       "25%       18.530000     23.153118\n",
       "50%       30.750000     28.390345\n",
       "75%       46.620000     39.919078\n",
       "max     2328.660000   1265.938009"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>1396.100993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>569.974941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>294.070957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>298.917059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>446.769011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>235.006230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-06-07</td>\n",
       "      <td>420.004928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-06-08</td>\n",
       "      <td>347.931534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-06-09</td>\n",
       "      <td>223.774698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>237.172035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-06-11</td>\n",
       "      <td>326.840541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>249.112527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>229.586621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-06-14</td>\n",
       "      <td>327.708766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-06-15</td>\n",
       "      <td>467.088767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-06-16</td>\n",
       "      <td>253.257534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-06-17</td>\n",
       "      <td>303.942895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>308.281737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>212.739618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>289.197831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date          mse\n",
       "0   2025-06-01  1396.100993\n",
       "1   2025-06-02   569.974941\n",
       "2   2025-06-03   294.070957\n",
       "3   2025-06-04   298.917059\n",
       "4   2025-06-05   446.769011\n",
       "5   2025-06-06   235.006230\n",
       "6   2025-06-07   420.004928\n",
       "7   2025-06-08   347.931534\n",
       "8   2025-06-09   223.774698\n",
       "9   2025-06-10   237.172035\n",
       "10  2025-06-11   326.840541\n",
       "11  2025-06-12   249.112527\n",
       "12  2025-06-13   229.586621\n",
       "13  2025-06-14   327.708766\n",
       "14  2025-06-15   467.088767\n",
       "15  2025-06-16   253.257534\n",
       "16  2025-06-17   303.942895\n",
       "17  2025-06-18   308.281737\n",
       "18  2025-06-19   212.739618\n",
       "19  2025-06-20   289.197831"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OOF vs target summary (raw scale)\n",
    "if CFG[\"use_log_target\"]:\n",
    "    y_raw = np.expm1(y_s.values).clip(min=0)\n",
    "    print(\"OOF MSE (raw):\", mean_squared_error(y_raw, oof))\n",
    "    display(pd.DataFrame({\"y\": y_raw, \"oof\": oof}).describe())\n",
    "else:\n",
    "    print(\"OOF MSE (raw):\", mean_squared_error(y_s.values, oof))\n",
    "    display(pd.DataFrame({\"y\": y_s.values, \"oof\": oof}).describe())\n",
    "\n",
    "# Per-day MSE to spot drift\n",
    "tmp = train_sess.assign(y=y_s.values, oof=oof)\n",
    "day_mse = tmp.groupby(tmp[\"session_start\"].dt.date).apply(lambda d: mean_squared_error(d[\"y\"], d[\"oof\"]))\n",
    "display(day_mse.to_frame(\"mse\").reset_index().rename(columns={\"session_start\":\"date\"}).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e36423",
   "metadata": {
    "papermill": {
     "duration": 0.00555,
     "end_time": "2025-08-29T07:02:07.139602",
     "exception": false,
     "start_time": "2025-08-29T07:02:07.134052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13341508,
     "sourceId": 112016,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 122.192507,
   "end_time": "2025-08-29T07:02:08.166981",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-29T07:00:05.974474",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
