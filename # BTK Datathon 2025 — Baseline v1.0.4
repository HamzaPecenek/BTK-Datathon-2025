{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e4bed7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:18:05.266287Z",
     "iopub.status.busy": "2025-08-30T07:18:05.265831Z",
     "iopub.status.idle": "2025-08-30T07:18:15.379526Z",
     "shell.execute_reply": "2025-08-30T07:18:15.378499Z"
    },
    "papermill": {
     "duration": 10.122501,
     "end_time": "2025-08-30T07:18:15.381278",
     "exception": false,
     "start_time": "2025-08-30T07:18:05.258777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================\n",
    "# BTK Datathon 2025 â€” Baseline v1.2 (micro)\n",
    "# Safe, incremental upgrades on your 1360 build\n",
    "# =============================\n",
    "\n",
    "import os, sys, gc, math, json, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# Config (keeps the working backbone)\n",
    "# -----------------------------\n",
    "CFG = {\n",
    "    \"seed\": 42,\n",
    "    \"seeds\": [42, 1024, 2048],                 # single seed (your best runs)\n",
    "    \"cv_type\": \"time\",             # DO NOT change (GroupKFold degraded LB earlier)\n",
    "    \"use_log_target\": False,       # DO NOT change (log target hurt LB)\n",
    "    \"add_user_history\": True,      # DO NOT turn off (turning off hurt LB)\n",
    "    \"add_sequence_extras\": True,\n",
    "\n",
    "    # Safe, proven LGBM core\n",
    "    \"lgb_params\": {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"mse\",\n",
    "        \"learning_rate\": 0.04,\n",
    "        \"num_leaves\": 60,\n",
    "        \"min_data_in_leaf\": 60,\n",
    "        \"feature_fraction\": 0.85,\n",
    "        \"bagging_fraction\": 0.85,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"lambda_l2\": 2.0,\n",
    "        \"max_depth\": -1,\n",
    "        \"verbosity\": -1,\n",
    "        \"force_row_wise\": True,\n",
    "        \"min_gain_to_split\": 0.01, # tiny guard vs noisy splits\n",
    "        \"extra_trees\": False,\n",
    "        \"seed\": 42, \"bagging_seed\": 42, \"feature_fraction_seed\": 42,\n",
    "        \"max_bin\": 255,\n",
    "    },\n",
    "\n",
    "    \"n_splits\": 3,\n",
    "    \"n_splits_group\": 5,\n",
    "    \"early_stopping_rounds\": 800,\n",
    "    \"num_boost_round\": 5000,\n",
    "\n",
    "    # Post-processing (remember: hard caps hurt; keep cap high)\n",
    "    \"clip\": {\"floor\": 0.0, \"cap\": 2000.0},\n",
    "\n",
    "    # --- New micro-upgrades (toggle easily) ---\n",
    "    \"add_micro_feats\": True,       # 4 small chronology ratios/timings\n",
    "    \"add_cyc_hour\": True,          # sin/cos hour\n",
    "    \"use_isotonic\": True,          # monotonic calibration on OOF (low risk)\n",
    "    \"submission_name\": \"submission_baseline_v1_0_4_3.csv\",\n",
    "\n",
    "    # new\n",
    "    \"use_isotonic\": True,\n",
    "    \"calib_blend\" : 0.65,\n",
    "}\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "set_seed(CFG[\"seed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225fa098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:18:15.392491Z",
     "iopub.status.busy": "2025-08-30T07:18:15.391207Z",
     "iopub.status.idle": "2025-08-30T07:18:15.403789Z",
     "shell.execute_reply": "2025-08-30T07:18:15.402657Z"
    },
    "papermill": {
     "duration": 0.019478,
     "end_time": "2025-08-30T07:18:15.405410",
     "exception": false,
     "start_time": "2025-08-30T07:18:15.385932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/datathon-2025/train.csv /kaggle/input/datathon-2025/test.csv /kaggle/input/datathon-2025/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# IO\n",
    "# -----------------------------\n",
    "CANDIDATE_DIRS = [Path(\"/kaggle/input/datathon-2025\")]\n",
    "def find_csv(filename: str) -> Path:\n",
    "    for d in CANDIDATE_DIRS:\n",
    "        p = d / filename\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"Could not find {filename} in {CANDIDATE_DIRS}\")\n",
    "\n",
    "train_path = find_csv(\"train.csv\")\n",
    "test_path  = find_csv(\"test.csv\")\n",
    "sub_path   = find_csv(\"sample_submission.csv\")\n",
    "print(train_path, test_path, sub_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f6208f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:18:15.415802Z",
     "iopub.status.busy": "2025-08-30T07:18:15.415012Z",
     "iopub.status.idle": "2025-08-30T07:18:16.581899Z",
     "shell.execute_reply": "2025-08-30T07:18:16.580779Z"
    },
    "papermill": {
     "duration": 1.173825,
     "end_time": "2025-08-30T07:18:16.583676",
     "exception": false,
     "start_time": "2025-08-30T07:18:15.409851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (141219, 7) (62951, 6) (30789, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "      <th>session_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06-19 10:23:07+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_011223</td>\n",
       "      <td>CAT_00054</td>\n",
       "      <td>USER_097562</td>\n",
       "      <td>SESSION_158779</td>\n",
       "      <td>90.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-06-07 21:34:45+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_005519</td>\n",
       "      <td>CAT_00144</td>\n",
       "      <td>USER_006535</td>\n",
       "      <td>SESSION_029987</td>\n",
       "      <td>16.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-21 21:29:09+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_000577</td>\n",
       "      <td>CAT_00273</td>\n",
       "      <td>USER_047199</td>\n",
       "      <td>SESSION_022134</td>\n",
       "      <td>64.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 event_time event_type   product_id category_id      user_id  \\\n",
       "0 2025-06-19 10:23:07+00:00   ADD_CART  PROD_011223   CAT_00054  USER_097562   \n",
       "1 2025-06-07 21:34:45+00:00   ADD_CART  PROD_005519   CAT_00144  USER_006535   \n",
       "2 2025-06-21 21:29:09+00:00   ADD_CART  PROD_000577   CAT_00273  USER_047199   \n",
       "\n",
       "     user_session  session_value  \n",
       "0  SESSION_158779          90.29  \n",
       "1  SESSION_029987          16.39  \n",
       "2  SESSION_022134          64.27  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06-28 10:09:58+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_015000</td>\n",
       "      <td>CAT_00019</td>\n",
       "      <td>USER_109759</td>\n",
       "      <td>SESSION_164059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-06-25 11:57:50+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_023887</td>\n",
       "      <td>CAT_00010</td>\n",
       "      <td>USER_010614</td>\n",
       "      <td>SESSION_109583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-30 14:34:20+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_022673</td>\n",
       "      <td>CAT_00090</td>\n",
       "      <td>USER_041338</td>\n",
       "      <td>SESSION_171382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 event_time event_type   product_id category_id      user_id  \\\n",
       "0 2025-06-28 10:09:58+00:00   ADD_CART  PROD_015000   CAT_00019  USER_109759   \n",
       "1 2025-06-25 11:57:50+00:00   ADD_CART  PROD_023887   CAT_00010  USER_010614   \n",
       "2 2025-06-30 14:34:20+00:00   ADD_CART  PROD_022673   CAT_00090  USER_041338   \n",
       "\n",
       "     user_session  \n",
       "0  SESSION_164059  \n",
       "1  SESSION_109583  \n",
       "2  SESSION_171382  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_session</th>\n",
       "      <th>session_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SESSION_164059</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SESSION_109583</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SESSION_171382</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_session  session_value\n",
       "0  SESSION_164059            0.0\n",
       "1  SESSION_109583            0.0\n",
       "2  SESSION_171382            0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 670 duplicate rows from train.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Read\n",
    "# -----------------------------\n",
    "def detect_time_col(cols):\n",
    "    cand = [c for c in cols if c.lower() in (\"event_time\", \"event_timestamp\", \"timestamp\", \"time\", \"event_datetime\")]\n",
    "    if cand: return cand[0]\n",
    "    cand = [c for c in cols if \"time\" in c.lower() or \"date\" in c.lower()]\n",
    "    return cand[0] if cand else None\n",
    "\n",
    "def read_df(path):\n",
    "    df = pd.read_csv(path)\n",
    "    tcol = detect_time_col(df.columns)\n",
    "    if tcol is None:\n",
    "        raise ValueError(\"Couldn't detect a time column. Please update detect_time_col().\")\n",
    "    df[tcol] = pd.to_datetime(df[tcol], errors=\"coerce\", utc=True)\n",
    "    if tcol != \"event_time\":\n",
    "        df = df.rename(columns={tcol: \"event_time\"})\n",
    "    return df\n",
    "\n",
    "train = read_df(train_path)\n",
    "test  = read_df(test_path)\n",
    "sub   = pd.read_csv(sub_path)\n",
    "\n",
    "TARGET_COL = \"session_value\"\n",
    "assert TARGET_COL in train.columns and TARGET_COL not in test.columns\n",
    "\n",
    "print(\"Shapes:\", train.shape, test.shape, sub.shape)\n",
    "\n",
    "display(train.head(3))\n",
    "display(test.head(3))\n",
    "display(sub.head(3))\n",
    "\n",
    "# Dedup (unchanged)\n",
    "before = len(train)\n",
    "train = train.drop_duplicates().reset_index(drop=True)\n",
    "after = len(train)\n",
    "print(f\"Dropped {before - after} duplicate rows from train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c23bd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:18:16.595098Z",
     "iopub.status.busy": "2025-08-30T07:18:16.594710Z",
     "iopub.status.idle": "2025-08-30T07:18:16.725009Z",
     "shell.execute_reply": "2025-08-30T07:18:16.723925Z"
    },
    "papermill": {
     "duration": 0.137842,
     "end_time": "2025-08-30T07:18:16.726617",
     "exception": false,
     "start_time": "2025-08-30T07:18:16.588775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event types: ['ADD_CART', 'BUY', 'REMOVE_CART', 'VIEW']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Typing / categories\n",
    "# -----------------------------\n",
    "ID_USER = \"user_id\"\n",
    "ID_SESSION = \"user_session\"\n",
    "PRODUCT_COL = \"product_id\"\n",
    "CATEGORY_COL = \"category_id\"\n",
    "EVENT_COL = \"event_type\"\n",
    "\n",
    "for df in (train, test):\n",
    "    for c in [ID_USER, ID_SESSION]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(str)\n",
    "    for c in [PRODUCT_COL, CATEGORY_COL, EVENT_COL]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(\"category\")\n",
    "\n",
    "if EVENT_COL in train.columns:\n",
    "    all_types = sorted(list(set(train[EVENT_COL].dropna().unique()).union(set(test[EVENT_COL].dropna().unique()))))\n",
    "    train[EVENT_COL] = train[EVENT_COL].cat.set_categories(all_types)\n",
    "    test[EVENT_COL]  = test[EVENT_COL].cat.set_categories(all_types)\n",
    "print(\"Event types:\", train[EVENT_COL].cat.categories.tolist() if EVENT_COL in train.columns else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f477964e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:18:16.737968Z",
     "iopub.status.busy": "2025-08-30T07:18:16.737620Z",
     "iopub.status.idle": "2025-08-30T07:18:59.601470Z",
     "shell.execute_reply": "2025-08-30T07:18:59.600431Z"
    },
    "papermill": {
     "duration": 42.87729,
     "end_time": "2025-08-30T07:18:59.608810",
     "exception": false,
     "start_time": "2025-08-30T07:18:16.731520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session tables built.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Session table (adds first_buy_time & time_to_buy_sec)\n",
    "# -----------------------------\n",
    "def build_session_table(events: pd.DataFrame, is_train: bool) -> pd.DataFrame:\n",
    "    df = events.copy()\n",
    "    df = df.sort_values([ID_SESSION, \"event_time\"]).reset_index(drop=True)\n",
    "\n",
    "    # per-event flags\n",
    "    df[\"is_buy\"]  = (df[EVENT_COL] == \"BUY\").astype(int)\n",
    "    df[\"is_add\"]  = (df[EVENT_COL] == \"ADD_CART\").astype(int)\n",
    "    df[\"is_rem\"]  = (df[EVENT_COL] == \"REMOVE_CART\").astype(int)\n",
    "    df[\"is_view\"] = (df[EVENT_COL] == \"VIEW\").astype(int)\n",
    "\n",
    "    df[\"ev_idx\"] = df.groupby(ID_SESSION).cumcount()\n",
    "\n",
    "    first_event = df.groupby(ID_SESSION)[EVENT_COL].first().rename(\"first_event_type\")\n",
    "    last_event  = df.groupby(ID_SESSION)[EVENT_COL].last().rename(\"last_event_type\")\n",
    "\n",
    "    t_start = df.groupby(ID_SESSION)[\"event_time\"].min().rename(\"session_start\")\n",
    "    t_end   = df.groupby(ID_SESSION)[\"event_time\"].max().rename(\"session_end\")\n",
    "    duration = (t_end - t_start).dt.total_seconds().rename(\"duration_sec\")\n",
    "\n",
    "    agg_counts = df.groupby(ID_SESSION).agg(\n",
    "        n_events     = (EVENT_COL, \"size\"),\n",
    "        n_products   = (PRODUCT_COL, pd.Series.nunique),\n",
    "        n_categories = (CATEGORY_COL, pd.Series.nunique),\n",
    "        n_event_types= (EVENT_COL, pd.Series.nunique),\n",
    "        cnt_buy      = (\"is_buy\", \"sum\"),\n",
    "        cnt_add      = (\"is_add\", \"sum\"),\n",
    "        cnt_rem      = (\"is_rem\", \"sum\"),\n",
    "        cnt_view     = (\"is_view\", \"sum\"),\n",
    "    )\n",
    "\n",
    "    has_buy = (agg_counts[\"cnt_buy\"] > 0).astype(int).rename(\"has_buy\")\n",
    "    first_buy_idx = (\n",
    "        df[df[\"is_buy\"] == 1]\n",
    "        .groupby(ID_SESSION)[\"ev_idx\"].min()\n",
    "        .reindex(agg_counts.index).fillna(-1).astype(int).rename(\"idx_first_buy\")\n",
    "    )\n",
    "\n",
    "    # NEW: first BUY time + time_to_buy_sec (fallback to duration if no BUY)\n",
    "    first_buy_time = (\n",
    "        df[df[\"is_buy\"] == 1]\n",
    "        .groupby(ID_SESSION)[\"event_time\"].min()\n",
    "        .reindex(agg_counts.index)\n",
    "        .rename(\"first_buy_time\")\n",
    "    )\n",
    "    time_to_buy_sec = (first_buy_time - t_start).dt.total_seconds().rename(\"time_to_buy_sec\")\n",
    "    time_to_buy_sec = time_to_buy_sec.fillna(duration)\n",
    "\n",
    "    events_after_buy = (agg_counts[\"n_events\"] - (first_buy_idx + 1)).clip(lower=0).rename(\"events_after_first_buy\")\n",
    "\n",
    "    tmp = df.merge(first_buy_idx.rename(\"fb\"), left_on=ID_SESSION, right_index=True, how=\"left\")\n",
    "    before_fb = tmp[\"ev_idx\"] <= tmp[\"fb\"]\n",
    "    cnt_add_before_buy = tmp.loc[before_fb, \"is_add\"].groupby(tmp[ID_SESSION]).sum().reindex(agg_counts.index).fillna(0).astype(int).rename(\"cnt_add_before_buy\")\n",
    "    cnt_rem_before_buy = tmp.loc[before_fb, \"is_rem\"].groupby(tmp[ID_SESSION]).sum().reindex(agg_counts.index).fillna(0).astype(int).rename(\"cnt_rem_before_buy\")\n",
    "\n",
    "    def count_transitions(g):\n",
    "        x = g[EVENT_COL].astype(str).values\n",
    "        if len(x) <= 1: return 0\n",
    "        return int((x[1:] != x[:-1]).sum())\n",
    "    n_transitions = df.groupby(ID_SESSION).apply(count_transitions).rename(\"n_transitions\")\n",
    "\n",
    "    start_hour = t_start.dt.hour.rename(\"start_hour\")\n",
    "    start_dow  = t_start.dt.dayofweek.rename(\"start_dow\")\n",
    "    start_day  = t_start.dt.day.rename(\"start_day\")\n",
    "\n",
    "    user_map = df.groupby(ID_SESSION)[ID_USER].first().rename(ID_USER)\n",
    "\n",
    "    sess = pd.concat(\n",
    "        [\n",
    "            t_start, t_end, duration, agg_counts,\n",
    "            has_buy, first_buy_idx, first_buy_time, time_to_buy_sec,\n",
    "            events_after_buy,\n",
    "            cnt_add_before_buy, cnt_rem_before_buy,\n",
    "            n_transitions, first_event, last_event,\n",
    "            start_hour, start_dow, start_day,\n",
    "            user_map,\n",
    "        ],\n",
    "        axis=1\n",
    "    ).reset_index()\n",
    "\n",
    "    if is_train:\n",
    "        t = df.groupby(ID_SESSION)[TARGET_COL].first().reset_index()\n",
    "        sess = sess.merge(t, on=ID_SESSION, how=\"left\")\n",
    "        chk = df.groupby(ID_SESSION)[TARGET_COL].nunique().max()\n",
    "        if chk != 1:\n",
    "            print(\"WARNING: session_value is not constant within sessions.\")\n",
    "\n",
    "    for c in [\"first_event_type\", \"last_event_type\"]:\n",
    "        if c in sess.columns:\n",
    "            sess[c] = sess[c].astype(\"category\")\n",
    "    sess[ID_USER] = sess[ID_USER].astype(str)\n",
    "    return sess\n",
    "\n",
    "train_sess = build_session_table(train, is_train=True)\n",
    "test_sess  = build_session_table(test,  is_train=False)\n",
    "print(\"Session tables built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb275697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:18:59.620094Z",
     "iopub.status.busy": "2025-08-30T07:18:59.619748Z",
     "iopub.status.idle": "2025-08-30T07:19:00.164480Z",
     "shell.execute_reply": "2025-08-30T07:19:00.163487Z"
    },
    "papermill": {
     "duration": 0.552313,
     "end_time": "2025-08-30T07:19:00.166104",
     "exception": false,
     "start_time": "2025-08-30T07:18:59.613791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user history features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_prev_n_sessions</th>\n",
       "      <th>user_prev_buy_rate</th>\n",
       "      <th>user_prev_mean_sv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.19813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.19813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.19813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_prev_n_sessions  user_prev_buy_rate  user_prev_mean_sv\n",
       "0                     0                 0.0           42.19813\n",
       "1                     0                 0.0           42.19813\n",
       "2                     0                 0.0           42.19813"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# User history (keep ON)\n",
    "# -----------------------------\n",
    "def add_user_history(train_sess: pd.DataFrame, test_sess: pd.DataFrame):\n",
    "    comb = pd.concat(\n",
    "        [train_sess.assign(_is_train=1), test_sess.assign(_is_train=0, **{TARGET_COL: np.nan})],\n",
    "        axis=0, ignore_index=True\n",
    "    ).sort_values([ID_USER, \"session_start\"]).reset_index(drop=True)\n",
    "\n",
    "    comb[\"user_prev_n_sessions\"] = comb.groupby(ID_USER).cumcount()\n",
    "\n",
    "    g = comb.groupby(ID_USER, sort=False)\n",
    "    pos = g.cumcount() + 1\n",
    "    prev_cnt = pos - 1\n",
    "    cum_sum_buy = g[\"has_buy\"].cumsum()\n",
    "    prev_sum_buy = cum_sum_buy - comb[\"has_buy\"]\n",
    "    comb[\"user_prev_buy_rate\"] = np.divide(\n",
    "        prev_sum_buy.astype(float), prev_cnt,\n",
    "        out=np.zeros_like(prev_sum_buy, dtype=float), where=prev_cnt > 0\n",
    "    )\n",
    "\n",
    "    comb[\"sv_notna\"]  = comb[TARGET_COL].notna().astype(int)\n",
    "    comb[\"sv_filled\"] = comb[TARGET_COL].fillna(0.0)\n",
    "    comb[\"cum_sum_sv\"] = g[\"sv_filled\"].cumsum()\n",
    "    comb[\"cum_cnt_sv\"] = g[\"sv_notna\"].cumsum()\n",
    "    prev_sum_sv = comb[\"cum_sum_sv\"] - comb[\"sv_filled\"]\n",
    "    prev_cnt_sv = comb[\"cum_cnt_sv\"] - comb[\"sv_notna\"]\n",
    "    prev_mean_sv = np.divide(\n",
    "        prev_sum_sv, prev_cnt_sv,\n",
    "        out=np.full(len(prev_sum_sv), np.nan, dtype=float), where=prev_cnt_sv > 0\n",
    "    )\n",
    "    global_mean_sv = float(train_sess[TARGET_COL].mean())\n",
    "    comb[\"user_prev_mean_sv\"] = np.where(np.isnan(prev_mean_sv), global_mean_sv, prev_mean_sv)\n",
    "\n",
    "    comb = comb.drop(columns=[\"sv_notna\",\"sv_filled\",\"cum_sum_sv\",\"cum_cnt_sv\"])\n",
    "\n",
    "    train_hist = comb[comb[\"_is_train\"] == 1].drop(columns=[\"_is_train\"])\n",
    "    test_hist  = comb[comb[\"_is_train\"] == 0].drop(columns=[\"_is_train\"])\n",
    "\n",
    "    for df in (train_hist, test_hist):\n",
    "        df[\"user_prev_n_sessions\"] = df[\"user_prev_n_sessions\"].astype(int)\n",
    "        df[\"user_prev_buy_rate\"]   = df[\"user_prev_buy_rate\"].astype(float)\n",
    "        df[\"user_prev_mean_sv\"]    = df[\"user_prev_mean_sv\"].astype(float)\n",
    "    return train_hist, test_hist\n",
    "\n",
    "if CFG[\"add_user_history\"]:\n",
    "    train_sess, test_sess = add_user_history(train_sess, test_sess)\n",
    "    print(\"Added user history features.\")\n",
    "    display(train_sess.filter(like=\"user_prev\").head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd6866eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:19:00.178063Z",
     "iopub.status.busy": "2025-08-30T07:19:00.177265Z",
     "iopub.status.idle": "2025-08-30T07:19:00.297706Z",
     "shell.execute_reply": "2025-08-30T07:19:00.296708Z"
    },
    "papermill": {
     "duration": 0.128195,
     "end_time": "2025-08-30T07:19:00.299445",
     "exception": false,
     "start_time": "2025-08-30T07:19:00.171250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added micro chronology features (and cyc hour if enabled).\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Micro features (small, targeted; safe)\n",
    "# -----------------------------\n",
    "def add_micro_features(sess: pd.DataFrame, add_cyc_hour=True) -> pd.DataFrame:\n",
    "    s = sess.copy()\n",
    "    ne = s[\"n_events\"].clip(lower=1)\n",
    "    fb = s[\"idx_first_buy\"]\n",
    "\n",
    "    # If no BUY, set as \"end\" (1.0); if BUY exists, relative position in [0,1]\n",
    "    denom = np.maximum(ne - 1, 1)\n",
    "    s[\"buy_pos_ratio\"] = np.where(fb >= 0, fb / denom, 1.0)\n",
    "\n",
    "    s[\"prebuy_add_share\"] = np.where(s[\"cnt_add\"] > 0, s[\"cnt_add_before_buy\"] / s[\"cnt_add\"], 0.0)\n",
    "    s[\"prebuy_rem_share\"] = np.where(s[\"cnt_rem\"] > 0, s[\"cnt_rem_before_buy\"] / s[\"cnt_rem\"], 0.0)\n",
    "\n",
    "    if add_cyc_hour and \"start_hour\" in s:\n",
    "        s[\"hour_sin\"] = np.sin(2*np.pi*s[\"start_hour\"] / 24.0)\n",
    "        s[\"hour_cos\"] = np.cos(2*np.pi*s[\"start_hour\"] / 24.0)\n",
    "    return s\n",
    "\n",
    "if CFG[\"add_micro_feats\"]:\n",
    "    train_sess = add_micro_features(train_sess, add_cyc_hour=CFG[\"add_cyc_hour\"])\n",
    "    test_sess  = add_micro_features(test_sess,  add_cyc_hour=CFG[\"add_cyc_hour\"])\n",
    "    print(\"Added micro chronology features (and cyc hour if enabled).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f69962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:19:00.312545Z",
     "iopub.status.busy": "2025-08-30T07:19:00.311656Z",
     "iopub.status.idle": "2025-08-30T07:19:00.319157Z",
     "shell.execute_reply": "2025-08-30T07:19:00.318136Z"
    },
    "papermill": {
     "duration": 0.016185,
     "end_time": "2025-08-30T07:19:00.320790",
     "exception": false,
     "start_time": "2025-08-30T07:19:00.304605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# (Optional) big enrichment set â€” KEEP OFF by default (hurt LB previously)\n",
    "# -----------------------------\n",
    "def enrich_small_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    eps = 1e-6\n",
    "    for c in [\"n_events\", \"n_products\", \"n_categories\", \"duration_sec\",\n",
    "              \"cnt_buy\", \"cnt_add\", \"cnt_rem\", \"cnt_view\"]:\n",
    "        if c in df: df[f\"log1p_{c}\"] = np.log1p(df[c].astype(float))\n",
    "    if \"n_events\" in df:\n",
    "        denom_ev = df[\"n_events\"].clip(lower=1).astype(float)\n",
    "        if \"cnt_add\" in df: df[\"rate_add_per_event\"] = df[\"cnt_add\"] / denom_ev\n",
    "        if \"cnt_rem\" in df: df[\"rate_rem_per_event\"] = df[\"cnt_rem\"] / denom_ev\n",
    "        if \"cnt_buy\" in df: df[\"rate_buy_per_event\"] = df[\"cnt_buy\"] / denom_ev\n",
    "    if \"duration_sec\" in df and \"n_events\" in df:\n",
    "        df[\"events_per_min\"] = df[\"n_events\"] / (df[\"duration_sec\"] / 60.0 + eps)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2cfeec0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:19:00.332759Z",
     "iopub.status.busy": "2025-08-30T07:19:00.331882Z",
     "iopub.status.idle": "2025-08-30T07:19:00.336831Z",
     "shell.execute_reply": "2025-08-30T07:19:00.335871Z"
    },
    "papermill": {
     "duration": 0.012528,
     "end_time": "2025-08-30T07:19:00.338381",
     "exception": false,
     "start_time": "2025-08-30T07:19:00.325853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Keep OFF (we learned these didnâ€™t transfer to LB)\n",
    "use_enrichments = False\n",
    "if use_enrichments:\n",
    "    train_sess = enrich_small_features(train_sess)\n",
    "    test_sess  = enrich_small_features(test_sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edc53b2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:19:00.349804Z",
     "iopub.status.busy": "2025-08-30T07:19:00.349464Z",
     "iopub.status.idle": "2025-08-30T07:19:00.358347Z",
     "shell.execute_reply": "2025-08-30T07:19:00.357311Z"
    },
    "papermill": {
     "duration": 0.016786,
     "end_time": "2025-08-30T07:19:00.360280",
     "exception": false,
     "start_time": "2025-08-30T07:19:00.343494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 29\n",
      "Categorical: ['first_event_type', 'last_event_type']\n",
      "Numeric: ['n_events', 'n_products', 'n_categories', 'n_event_types', 'cnt_buy', 'cnt_add', 'cnt_rem', 'cnt_view', 'duration_sec', 'has_buy', 'idx_first_buy', 'events_after_first_buy', 'cnt_add_before_buy', 'cnt_rem_before_buy', 'n_transitions', 'start_hour', 'start_dow', 'start_day', 'time_to_buy_sec', 'user_prev_n_sessions', 'user_prev_buy_rate', 'user_prev_mean_sv', 'buy_pos_ratio', 'prebuy_add_share', 'prebuy_rem_share', 'hour_sin', 'hour_cos']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Features\n",
    "# -----------------------------\n",
    "categorical_cols = [\"first_event_type\", \"last_event_type\"]\n",
    "numeric_cols = [\n",
    "    \"n_events\",\"n_products\",\"n_categories\",\"n_event_types\",\n",
    "    \"cnt_buy\",\"cnt_add\",\"cnt_rem\",\"cnt_view\",\n",
    "    \"duration_sec\",\"has_buy\",\"idx_first_buy\",\"events_after_first_buy\",\n",
    "    \"cnt_add_before_buy\",\"cnt_rem_before_buy\",\"n_transitions\",\n",
    "    \"start_hour\",\"start_dow\",\"start_day\",\n",
    "    \"time_to_buy_sec\",\n",
    "]\n",
    "if CFG[\"add_user_history\"]:\n",
    "    numeric_cols += [\"user_prev_n_sessions\",\"user_prev_buy_rate\",\"user_prev_mean_sv\"]\n",
    "\n",
    "# micro feats\n",
    "if CFG[\"add_micro_feats\"]:\n",
    "    micro_cols = [\"buy_pos_ratio\",\"prebuy_add_share\",\"prebuy_rem_share\"]\n",
    "    numeric_cols += [c for c in micro_cols if c in train_sess.columns]\n",
    "if CFG[\"add_cyc_hour\"]:\n",
    "    cyc_cols = [\"hour_sin\",\"hour_cos\"]\n",
    "    numeric_cols += [c for c in cyc_cols if c in train_sess.columns]\n",
    "\n",
    "categorical_cols = [c for c in categorical_cols if c in train_sess.columns]\n",
    "numeric_cols     = [c for c in numeric_cols if c in train_sess.columns]\n",
    "FEATS = categorical_cols + numeric_cols\n",
    "\n",
    "print(\"Num features:\", len(FEATS))\n",
    "print(\"Categorical:\", categorical_cols)\n",
    "print(\"Numeric:\", [c for c in FEATS if c not in categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cd41bf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:19:00.372496Z",
     "iopub.status.busy": "2025-08-30T07:19:00.372146Z",
     "iopub.status.idle": "2025-08-30T07:19:00.399004Z",
     "shell.execute_reply": "2025-08-30T07:19:00.397966Z"
    },
    "papermill": {
     "duration": 0.034968,
     "end_time": "2025-08-30T07:19:00.400642",
     "exception": false,
     "start_time": "2025-08-30T07:19:00.365674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70736, 29) (30789, 29)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Target\n",
    "# -----------------------------\n",
    "if CFG[\"use_log_target\"]:\n",
    "    train_sess[\"target\"] = np.log1p(train_sess[TARGET_COL].clip(lower=0))\n",
    "else:\n",
    "    train_sess[\"target\"] = train_sess[TARGET_COL].astype(float)\n",
    "\n",
    "for c in categorical_cols:\n",
    "    train_sess[c] = train_sess[c].astype(\"category\")\n",
    "    test_sess[c]  = test_sess[c].astype(\"category\")\n",
    "\n",
    "X = train_sess[FEATS].copy()\n",
    "y = train_sess[\"target\"].values\n",
    "X_test = test_sess[FEATS].copy()\n",
    "y_s = pd.Series(train_sess[\"target\"].values, index=X.index)\n",
    "\n",
    "print(X.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8246e62d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:19:00.412947Z",
     "iopub.status.busy": "2025-08-30T07:19:00.412217Z",
     "iopub.status.idle": "2025-08-30T07:19:00.477971Z",
     "shell.execute_reply": "2025-08-30T07:19:00.476746Z"
    },
    "papermill": {
     "duration": 0.073754,
     "end_time": "2025-08-30T07:19:00.479654",
     "exception": false,
     "start_time": "2025-08-30T07:19:00.405900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Fold 0: val window 2025-06-01 00:00:24+00:00 â†’ 2025-06-07 03:06:40+00:00, size=23579\n",
      "Time Fold 1: val window 2025-06-07 03:06:51+00:00 â†’ 2025-06-14 09:07:02+00:00, size=23579\n",
      "Time Fold 2: val window 2025-06-14 09:07:35+00:00 â†’ 2025-06-21 23:58:05+00:00, size=23578\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# CV helpers (KEEP the original time windows â€” changing split hurt LB)\n",
    "# -----------------------------\n",
    "def make_time_folds(df: pd.DataFrame, n_splits=3, date_col=\"session_start\"):\n",
    "    df_sorted = df.sort_values(date_col).reset_index()\n",
    "    n = len(df_sorted)\n",
    "    fold_sizes = [n // n_splits] * n_splits\n",
    "    for i in range(n % n_splits):\n",
    "        fold_sizes[i] += 1\n",
    "    idxs, start = [], 0\n",
    "    for fs in fold_sizes:\n",
    "        end = start + fs\n",
    "        idxs.append(df_sorted.loc[start:end-1, \"index\"].values)\n",
    "        start = end\n",
    "    folds = []\n",
    "    for i in range(n_splits):\n",
    "        val_idx = idxs[i]\n",
    "        tr_idx = np.concatenate([idxs[j] for j in range(n_splits) if j != i])\n",
    "        folds.append((tr_idx, val_idx))\n",
    "    return folds\n",
    "\n",
    "def make_group_folds(df: pd.DataFrame, n_splits=5, group_col=ID_USER):\n",
    "    idx = np.arange(len(df))\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    return [(tr, va) for tr, va in gkf.split(idx, groups=df[group_col].values)]\n",
    "\n",
    "folds_preview = make_time_folds(train_sess, n_splits=CFG[\"n_splits\"], date_col=\"session_start\")\n",
    "for i, (_, va) in enumerate(folds_preview):\n",
    "    d1 = train_sess.loc[va, \"session_start\"].min()\n",
    "    d2 = train_sess.loc[va, \"session_start\"].max()\n",
    "    print(f\"Time Fold {i}: val window {d1} â†’ {d2}, size={len(va)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47a923e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:19:00.491943Z",
     "iopub.status.busy": "2025-08-30T07:19:00.491614Z",
     "iopub.status.idle": "2025-08-30T07:24:32.858886Z",
     "shell.execute_reply": "2025-08-30T07:24:32.858073Z"
    },
    "papermill": {
     "duration": 332.375612,
     "end_time": "2025-08-30T07:24:32.860584",
     "exception": false,
     "start_time": "2025-08-30T07:19:00.484972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[seed 42] Fold 0: best_iter=3039, val_size=23579\n",
      "[seed 42] Fold 1: best_iter=236, val_size=23579\n",
      "[seed 42] Fold 2: best_iter=3172, val_size=23578\n",
      "[seed 1024] Fold 0: best_iter=4404, val_size=23579\n",
      "[seed 1024] Fold 1: best_iter=357, val_size=23579\n",
      "[seed 1024] Fold 2: best_iter=2851, val_size=23578\n",
      "[seed 2048] Fold 0: best_iter=4224, val_size=23579\n",
      "[seed 2048] Fold 1: best_iter=306, val_size=23579\n",
      "[seed 2048] Fold 2: best_iter=4034, val_size=23578\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Train / OOF / Test\n",
    "# -----------------------------\n",
    "oof_all = np.zeros(len(X), dtype=float)\n",
    "test_preds_seeds = []\n",
    "feat_imps = []\n",
    "\n",
    "global_mean_sv = float(train_sess[TARGET_COL].mean())\n",
    "X_index = pd.Index(X.index)\n",
    "\n",
    "for seed in CFG[\"seeds\"]:\n",
    "    lgb_params = CFG[\"lgb_params\"].copy()\n",
    "    lgb_params.update({\"seed\": seed, \"bagging_seed\": seed, \"feature_fraction_seed\": seed})\n",
    "    set_seed(seed)\n",
    "\n",
    "    if CFG[\"cv_type\"] == \"time\":\n",
    "        folds = make_time_folds(train_sess, n_splits=CFG[\"n_splits\"], date_col=\"session_start\")\n",
    "    else:\n",
    "        folds = make_group_folds(train_sess, n_splits=CFG[\"n_splits_group\"], group_col=ID_USER)\n",
    "\n",
    "    oof_seed = np.zeros(len(X), dtype=float)\n",
    "    best_iters = []\n",
    "\n",
    "    for i, (tr_idx, va_idx) in enumerate(folds):\n",
    "        tr_pos = X_index.get_indexer(tr_idx)\n",
    "        va_pos = X_index.get_indexer(va_idx)\n",
    "        if (tr_pos < 0).any() or (va_pos < 0).any():\n",
    "            raise ValueError(f\"Fold {i}: indices not present in X.index.\")\n",
    "        if (va_pos >= len(X)).any() or (tr_pos >= len(X)).any():\n",
    "            raise ValueError(f\"Fold {i}: positional index out of bounds.\")\n",
    "\n",
    "        X_tr, y_tr = X.iloc[tr_pos], y_s.iloc[tr_pos].values\n",
    "        X_va, y_va = X.iloc[va_pos], y_s.iloc[va_pos].values\n",
    "\n",
    "        # (Remember: when we used group CV + history, mismatch hurt LB; leave as-is for time CV)\n",
    "        if CFG[\"cv_type\"] != \"time\":\n",
    "            X_va = X_va.copy()\n",
    "            if \"user_prev_mean_sv\" in X_va: X_va[\"user_prev_mean_sv\"] = global_mean_sv\n",
    "            if \"user_prev_buy_rate\" in X_va: X_va[\"user_prev_buy_rate\"] = 0.0\n",
    "            if \"user_prev_n_sessions\" in X_va: X_va[\"user_prev_n_sessions\"] = 0\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_tr, label=y_tr, categorical_feature=categorical_cols, free_raw_data=False)\n",
    "        lgb_valid = lgb.Dataset(X_va, label=y_va, categorical_feature=categorical_cols, free_raw_data=False)\n",
    "\n",
    "        model = lgb.train(\n",
    "            lgb_params, lgb_train,\n",
    "            num_boost_round=CFG[\"num_boost_round\"],\n",
    "            valid_sets=[lgb_train, lgb_valid],\n",
    "            valid_names=[\"train\", \"valid\"],\n",
    "            callbacks=[lgb.early_stopping(CFG[\"early_stopping_rounds\"], verbose=False)]\n",
    "        )\n",
    "        best_iters.append(model.best_iteration)\n",
    "\n",
    "        pred_va = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "        if CFG[\"use_log_target\"]:\n",
    "            pred_va = np.expm1(pred_va).clip(min=0)\n",
    "        pred_va = np.clip(pred_va, CFG[\"clip\"][\"floor\"], CFG[\"clip\"][\"cap\"])\n",
    "\n",
    "        oof_seed[va_pos] = pred_va\n",
    "\n",
    "        fi = pd.DataFrame({\n",
    "            \"feature\": FEATS,\n",
    "            \"gain\": model.feature_importance(importance_type=\"gain\"),\n",
    "            \"split\": model.feature_importance(importance_type=\"split\"),\n",
    "            \"fold\": i,\n",
    "            \"seed\": seed,\n",
    "        })\n",
    "        feat_imps.append(fi)\n",
    "\n",
    "        print(f\"[seed {seed}] Fold {i}: best_iter={model.best_iteration}, val_size={len(va_pos)}\")\n",
    "\n",
    "    oof_all += oof_seed / len(CFG[\"seeds\"])\n",
    "\n",
    "    full_iters = int(np.mean(best_iters))\n",
    "    full_ds = lgb.Dataset(X, label=y_s.values, categorical_feature=categorical_cols, free_raw_data=False)\n",
    "    full_model = lgb.train(lgb_params, full_ds, num_boost_round=full_iters)\n",
    "\n",
    "    pred_test = full_model.predict(X_test)\n",
    "    if CFG[\"use_log_target\"]:\n",
    "        pred_test = np.expm1(pred_test).clip(min=0)\n",
    "    pred_test = np.clip(pred_test, CFG[\"clip\"][\"floor\"], CFG[\"clip\"][\"cap\"])\n",
    "    test_preds_seeds.append(pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6afcae15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:24:32.873871Z",
     "iopub.status.busy": "2025-08-30T07:24:32.873568Z",
     "iopub.status.idle": "2025-08-30T07:24:32.935997Z",
     "shell.execute_reply": "2025-08-30T07:24:32.934882Z"
    },
    "papermill": {
     "duration": 0.071001,
     "end_time": "2025-08-30T07:24:32.937725",
     "exception": false,
     "start_time": "2025-08-30T07:24:32.866724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF MSE (pre-calibration, post-processed): 375.8477\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnt_buy</td>\n",
       "      <td>6.086731e+08</td>\n",
       "      <td>4617.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>events_after_first_buy</td>\n",
       "      <td>1.205673e+08</td>\n",
       "      <td>4992.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>has_buy</td>\n",
       "      <td>6.916401e+07</td>\n",
       "      <td>69.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n_products</td>\n",
       "      <td>3.972979e+07</td>\n",
       "      <td>5608.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnt_add</td>\n",
       "      <td>3.775312e+07</td>\n",
       "      <td>4012.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n_events</td>\n",
       "      <td>2.946480e+07</td>\n",
       "      <td>5474.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>duration_sec</td>\n",
       "      <td>2.895250e+07</td>\n",
       "      <td>17028.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n_categories</td>\n",
       "      <td>2.351585e+07</td>\n",
       "      <td>5354.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>buy_pos_ratio</td>\n",
       "      <td>2.059552e+07</td>\n",
       "      <td>2809.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>idx_first_buy</td>\n",
       "      <td>2.049658e+07</td>\n",
       "      <td>2703.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>time_to_buy_sec</td>\n",
       "      <td>9.876913e+06</td>\n",
       "      <td>11623.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hour_cos</td>\n",
       "      <td>9.242607e+06</td>\n",
       "      <td>7805.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cnt_rem</td>\n",
       "      <td>9.042078e+06</td>\n",
       "      <td>3026.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>user_prev_n_sessions</td>\n",
       "      <td>8.290781e+06</td>\n",
       "      <td>5862.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>last_event_type</td>\n",
       "      <td>7.725509e+06</td>\n",
       "      <td>1768.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>user_prev_mean_sv</td>\n",
       "      <td>7.709268e+06</td>\n",
       "      <td>16675.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hour_sin</td>\n",
       "      <td>7.659321e+06</td>\n",
       "      <td>6879.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>start_dow</td>\n",
       "      <td>6.980761e+06</td>\n",
       "      <td>8145.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>start_day</td>\n",
       "      <td>6.966603e+06</td>\n",
       "      <td>10746.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>start_hour</td>\n",
       "      <td>5.706980e+06</td>\n",
       "      <td>9441.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>n_transitions</td>\n",
       "      <td>5.560441e+06</td>\n",
       "      <td>2575.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cnt_add_before_buy</td>\n",
       "      <td>5.091270e+06</td>\n",
       "      <td>1108.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cnt_view</td>\n",
       "      <td>4.706667e+06</td>\n",
       "      <td>3324.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>n_event_types</td>\n",
       "      <td>4.552607e+06</td>\n",
       "      <td>1647.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>first_event_type</td>\n",
       "      <td>4.037894e+06</td>\n",
       "      <td>1669.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cnt_rem_before_buy</td>\n",
       "      <td>3.016689e+06</td>\n",
       "      <td>1458.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>prebuy_add_share</td>\n",
       "      <td>1.478620e+06</td>\n",
       "      <td>330.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>user_prev_buy_rate</td>\n",
       "      <td>1.038438e+06</td>\n",
       "      <td>1378.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>prebuy_rem_share</td>\n",
       "      <td>3.503922e+05</td>\n",
       "      <td>170.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature          gain         split\n",
       "0                  cnt_buy  6.086731e+08   4617.555556\n",
       "1   events_after_first_buy  1.205673e+08   4992.000000\n",
       "2                  has_buy  6.916401e+07     69.666667\n",
       "3               n_products  3.972979e+07   5608.777778\n",
       "4                  cnt_add  3.775312e+07   4012.333333\n",
       "5                 n_events  2.946480e+07   5474.444444\n",
       "6             duration_sec  2.895250e+07  17028.111111\n",
       "7             n_categories  2.351585e+07   5354.555556\n",
       "8            buy_pos_ratio  2.059552e+07   2809.111111\n",
       "9            idx_first_buy  2.049658e+07   2703.111111\n",
       "10         time_to_buy_sec  9.876913e+06  11623.333333\n",
       "11                hour_cos  9.242607e+06   7805.888889\n",
       "12                 cnt_rem  9.042078e+06   3026.222222\n",
       "13    user_prev_n_sessions  8.290781e+06   5862.222222\n",
       "14         last_event_type  7.725509e+06   1768.222222\n",
       "15       user_prev_mean_sv  7.709268e+06  16675.000000\n",
       "16                hour_sin  7.659321e+06   6879.111111\n",
       "17               start_dow  6.980761e+06   8145.888889\n",
       "18               start_day  6.966603e+06  10746.333333\n",
       "19              start_hour  5.706980e+06   9441.777778\n",
       "20           n_transitions  5.560441e+06   2575.444444\n",
       "21      cnt_add_before_buy  5.091270e+06   1108.222222\n",
       "22                cnt_view  4.706667e+06   3324.444444\n",
       "23           n_event_types  4.552607e+06   1647.555556\n",
       "24        first_event_type  4.037894e+06   1669.555556\n",
       "25      cnt_rem_before_buy  3.016689e+06   1458.222222\n",
       "26        prebuy_add_share  1.478620e+06    330.333333\n",
       "27      user_prev_buy_rate  1.038438e+06   1378.111111\n",
       "28        prebuy_rem_share  3.503922e+05    170.777778"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test pred summary (pre-calibration):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    30789.000000\n",
       "mean        43.732804\n",
       "std         44.433206\n",
       "min          0.178758\n",
       "25%         23.757244\n",
       "50%         29.672813\n",
       "75%         42.991210\n",
       "max        930.058400\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Metrics & FI\n",
    "# -----------------------------\n",
    "if CFG[\"use_log_target\"]:\n",
    "    y_raw = np.expm1(y_s.values)\n",
    "    oof_mse = mean_squared_error(y_raw, oof_all)\n",
    "else:\n",
    "    y_raw = y_s.values\n",
    "    oof_mse = mean_squared_error(y_raw, oof_all)\n",
    "print(f\"OOF MSE (pre-calibration, post-processed): {oof_mse:,.4f}\")\n",
    "\n",
    "feat_importance = (\n",
    "    pd.concat(feat_imps, ignore_index=True)\n",
    "      .groupby(\"feature\")[[\"gain\",\"split\"]].mean()\n",
    "      .sort_values(\"gain\", ascending=False).reset_index()\n",
    ")\n",
    "display(feat_importance.head(30))\n",
    "\n",
    "test_pred = np.mean(test_preds_seeds, axis=0)\n",
    "print(\"Test pred summary (pre-calibration):\")\n",
    "display(pd.Series(test_pred).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f41fcefd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:24:32.951854Z",
     "iopub.status.busy": "2025-08-30T07:24:32.951468Z",
     "iopub.status.idle": "2025-08-30T07:24:32.995565Z",
     "shell.execute_reply": "2025-08-30T07:24:32.994282Z"
    },
    "papermill": {
     "duration": 0.05331,
     "end_time": "2025-08-30T07:24:32.997410",
     "exception": false,
     "start_time": "2025-08-30T07:24:32.944100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF MSE (raw): 375.84774679972054\n",
      "OOF MSE (iso): 332.0368143222168\n",
      "OOF MSE (blend): 338.7949743425287\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Isotonic calibration (OPTIONAL but ON by default)\n",
    "# -----------------------------\n",
    "test_pred_raw = np.mean(test_preds_seeds, axis=0)\n",
    "\n",
    "if CFG[\"use_isotonic\"]:\n",
    "    iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "    iso.fit(oof_all, y_raw)\n",
    "\n",
    "    oof_cal  = np.clip(iso.predict(oof_all), CFG[\"clip\"][\"floor\"], CFG[\"clip\"][\"cap\"])\n",
    "    oof_base = oof_all\n",
    "\n",
    "    # Blend OOF for reporting\n",
    "    oof_blend = CFG[\"calib_blend\"] * oof_cal + (1 - CFG[\"calib_blend\"]) * oof_base\n",
    "    print(\"OOF MSE (raw):\", mean_squared_error(y_raw, oof_base))\n",
    "    print(\"OOF MSE (iso):\", mean_squared_error(y_raw, oof_cal))\n",
    "    print(\"OOF MSE (blend):\", mean_squared_error(y_raw, oof_blend))\n",
    "\n",
    "    # Blend TEST the same way\n",
    "    test_pred_cal = np.clip(iso.predict(test_pred_raw), CFG[\"clip\"][\"floor\"], CFG[\"clip\"][\"cap\"])\n",
    "    test_pred = CFG[\"calib_blend\"] * test_pred_cal + (1 - CFG[\"calib_blend\"]) * test_pred_raw\n",
    "else:\n",
    "    test_pred = test_pred_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "923b4f74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:24:33.011999Z",
     "iopub.status.busy": "2025-08-30T07:24:33.011528Z",
     "iopub.status.idle": "2025-08-30T07:24:33.141989Z",
     "shell.execute_reply": "2025-08-30T07:24:33.141059Z"
    },
    "papermill": {
     "duration": 0.139566,
     "end_time": "2025-08-30T07:24:33.143661",
     "exception": false,
     "start_time": "2025-08-30T07:24:33.004095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: submission_baseline_v1_0_4_4.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_session</th>\n",
       "      <th>session_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SESSION_164059</td>\n",
       "      <td>158.487030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SESSION_109583</td>\n",
       "      <td>38.880898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SESSION_171382</td>\n",
       "      <td>40.592660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SESSION_137110</td>\n",
       "      <td>33.482757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SESSION_146503</td>\n",
       "      <td>191.981665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_session  session_value\n",
       "0  SESSION_164059     158.487030\n",
       "1  SESSION_109583      38.880898\n",
       "2  SESSION_171382      40.592660\n",
       "3  SESSION_137110      33.482757\n",
       "4  SESSION_146503     191.981665"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Expect submission format: [\"user_session\", \"session_value\"]\n",
    "sub_out = sub.copy()\n",
    "key = \"user_session\"\n",
    "\n",
    "# Map predictions by user_session (test_sess has one row per session)\n",
    "pred_map = dict(zip(test_sess[key], test_pred))\n",
    "sub_out[TARGET_COL] = sub_out[key].map(pred_map).fillna(CFG[\"clip\"][\"floor\"])\n",
    "\n",
    "save_name = \"submission_baseline_v1_0_4_4.csv\"\n",
    "sub_out.to_csv(save_name, index=False)\n",
    "print(\"Saved:\", save_name)\n",
    "display(sub_out.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18bab00b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T07:24:33.157735Z",
     "iopub.status.busy": "2025-08-30T07:24:33.157403Z",
     "iopub.status.idle": "2025-08-30T07:24:33.241649Z",
     "shell.execute_reply": "2025-08-30T07:24:33.240642Z"
    },
    "papermill": {
     "duration": 0.093305,
     "end_time": "2025-08-30T07:24:33.243308",
     "exception": false,
     "start_time": "2025-08-30T07:24:33.150003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF MSE (final used for reporting): 332.0368143222168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>650.491096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>511.729414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>300.267395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>291.492816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>456.436872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>237.864559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-06-07</td>\n",
       "      <td>418.301317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-06-08</td>\n",
       "      <td>325.549283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-06-09</td>\n",
       "      <td>215.447132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>225.980367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-06-11</td>\n",
       "      <td>329.996431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>247.704282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>243.914959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-06-14</td>\n",
       "      <td>308.733770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-06-15</td>\n",
       "      <td>298.555255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-06-16</td>\n",
       "      <td>243.667637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-06-17</td>\n",
       "      <td>318.534620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>278.440127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>210.584577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>459.353447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date         mse\n",
       "0   2025-06-01  650.491096\n",
       "1   2025-06-02  511.729414\n",
       "2   2025-06-03  300.267395\n",
       "3   2025-06-04  291.492816\n",
       "4   2025-06-05  456.436872\n",
       "5   2025-06-06  237.864559\n",
       "6   2025-06-07  418.301317\n",
       "7   2025-06-08  325.549283\n",
       "8   2025-06-09  215.447132\n",
       "9   2025-06-10  225.980367\n",
       "10  2025-06-11  329.996431\n",
       "11  2025-06-12  247.704282\n",
       "12  2025-06-13  243.914959\n",
       "13  2025-06-14  308.733770\n",
       "14  2025-06-15  298.555255\n",
       "15  2025-06-16  243.667637\n",
       "16  2025-06-17  318.534620\n",
       "17  2025-06-18  278.440127\n",
       "18  2025-06-19  210.584577\n",
       "19  2025-06-20  459.353447"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Diagnostics\n",
    "# -----------------------------\n",
    "print(\"OOF MSE (final used for reporting):\",\n",
    "      mean_squared_error(y_raw, oof_cal if CFG[\"use_isotonic\"] else oof_all))\n",
    "tmp = train_sess.assign(y=y_raw, oof=(oof_cal if CFG[\"use_isotonic\"] else oof_all))\n",
    "day_mse = tmp.groupby(tmp[\"session_start\"].dt.date).apply(lambda d: mean_squared_error(d[\"y\"], d[\"oof\"]))\n",
    "display(day_mse.to_frame(\"mse\").reset_index().rename(columns={\"session_start\":\"date\"}).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df1b28",
   "metadata": {
    "papermill": {
     "duration": 0.006408,
     "end_time": "2025-08-30T07:24:33.256433",
     "exception": false,
     "start_time": "2025-08-30T07:24:33.250025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13341508,
     "sourceId": 112016,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 395.128691,
   "end_time": "2025-08-30T07:24:34.386758",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-30T07:17:59.258067",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
